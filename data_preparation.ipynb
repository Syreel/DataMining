{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "c1590ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "1704c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = 'dataset/artists.csv'\n",
    "tracks = 'dataset/tracks.csv'\n",
    "\n",
    "index_col = 0\n",
    "df_artists = pd.read_csv(artists, sep=';', index_col=index_col)\n",
    "df_tracks = pd.read_csv(tracks, index_col=index_col)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ca4ffe",
   "metadata": {},
   "source": [
    "## üíæ Optimizing Data Types for Efficiency\n",
    "\n",
    "Before we proceed with cleaning and analysis, it's essential to ensure our DataFrames use the most **memory-efficient and appropriate data types**. Converting low-cardinality string columns (like `gender` and `nationality`) to the **`category`** dtype significantly reduces memory usage.\n",
    "\n",
    "We'll also ensure all date columns are correctly parsed as **`datetime`** objects, and descriptive text fields are designated as the modern **`string`** dtype. For integer columns that contain `NaN` values, we use the nullable integer type **`Int64`**.\n",
    "\n",
    "This step makes subsequent operations faster and more memory-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "75ab7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists['gender'] = df_artists['gender'].astype('category')\n",
    "df_artists['nationality'] = df_artists['nationality'].astype('category')\n",
    "df_artists['country'] = df_artists['country'].astype('category')\n",
    "df_artists['region'] = df_artists['region'].astype('category')\n",
    "df_artists['province'] = df_artists['province'].astype('category')\n",
    "df_artists['birth_place'] = df_artists['birth_place'].astype('category')\n",
    "df_artists['birth_date'] = pd.to_datetime(df_artists['birth_date'], errors='coerce')\n",
    "df_artists['active_start'] = pd.to_datetime(df_artists['active_start'], errors='coerce')\n",
    "df_artists['description'] = df_artists['description'].astype('string')\n",
    "df_artists['name'] = df_artists['name'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "aae007ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks['id_artist'] = df_tracks['id_artist'].astype('category')\n",
    "df_tracks['id_album'] = df_tracks['id_album'].astype('category')\n",
    "df_tracks['language'] = df_tracks['language'].astype('category')\n",
    "df_tracks['album_type'] = df_tracks['album_type'].astype('category')\n",
    "df_tracks['stats_pageviews'] = pd.to_numeric(df_tracks['stats_pageviews'], errors='coerce')\n",
    "df_tracks['year'] = pd.to_numeric(df_tracks['year'], errors='coerce')\n",
    "df_tracks['month'] = pd.to_numeric(df_tracks['month'], errors='coerce')\n",
    "df_tracks['day'] = pd.to_numeric(df_tracks['day'], errors='coerce')\n",
    "df_tracks['popularity'] = pd.to_numeric(df_tracks['popularity'], errors='coerce')\n",
    "df_tracks['disc_number'] = df_tracks['disc_number'].astype('Int64')\n",
    "df_tracks['track_number'] = df_tracks['track_number'].astype('Int64')\n",
    "df_tracks['explicit'] = df_tracks['explicit'].astype('bool')\n",
    "df_tracks['modified_popularity'] = df_tracks['modified_popularity'].astype('bool')\n",
    "df_tracks['album_release_date'] = pd.to_datetime(df_tracks['album_release_date'], errors='coerce')\n",
    "df_tracks['name_artist'] = df_tracks['name_artist'].astype('string')\n",
    "df_tracks['full_title'] = df_tracks['full_title'].astype('string')\n",
    "df_tracks['title'] = df_tracks['title'].astype('string')\n",
    "df_tracks['featured_artists'] = df_tracks['featured_artists'].astype('string')\n",
    "df_tracks['primary_artist'] = df_tracks['primary_artist'].astype('string')\n",
    "df_tracks['album_name'] = df_tracks['album_name'].astype('string')\n",
    "df_tracks['album'] = df_tracks['album'].astype('string')\n",
    "df_tracks['album_image'] = df_tracks['album_image'].astype('string')\n",
    "df_tracks['lyrics'] = df_tracks['lyrics'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "482f10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # Import the Abstract Syntax Tree module for safe evaluation\n",
    "\n",
    "# Assuming your DataFrame is df_tracks and it's already loaded\n",
    "\n",
    "def safe_literal_eval(value):\n",
    "    \"\"\"\n",
    "    Safely converts a string representation of a list into a Python list.\n",
    "    Handles NaN/missing values by returning an empty list or pd.NA.\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value in (None, 'NaN', ''):\n",
    "        # Return an empty list for missing values if you plan to iterate over it\n",
    "        return []\n",
    "    try:\n",
    "        # Use ast.literal_eval for safe conversion of string-to-list\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Handle cases where the string is malformed or not a list structure\n",
    "        print(f\"Warning: Could not convert value: {value}\")\n",
    "        return [] # Default to empty list on failure\n",
    "\n",
    "# Apply the conversion to both columns\n",
    "df_tracks['swear_IT_words'] = df_tracks['swear_IT_words'].apply(safe_literal_eval)\n",
    "df_tracks['swear_EN_words'] = df_tracks['swear_EN_words'].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab69d5",
   "metadata": {},
   "source": [
    "## üïµÔ∏è Data Validation: Checking and Correcting Primary Key Duplicates\n",
    "\n",
    "For the data preparation phase, we start by performing a crucial check of the primary IDs for rows in both our DataFrames to check for potential duplicates. Ensuring unique identifiers is **foundational** for reliable joins and accurate analysis later on. \n",
    "\n",
    "A formal review of the primary ID columns yielded the following observations:\n",
    "\n",
    "* **`df_tracks`**: Inspection of the track ID column revealed **73 instances of duplicated identifiers**. To guarantee that each record is uniquely identifiable and to maintain the principle of one-to-one entity mapping, these duplicated rows will be managed immediately. IDs are of the format $\\text{TR\\#\\#\\#\\#\\#\\#}$, so we generate new IDs compliant with this format to replace duplicated ones.\n",
    "* **`df_artists`**: The artist ID column was found to be **entirely sound**, presenting no instances of duplicate IDs. Consequently, no corrective action is required for this DataFrame regarding its primary keys.\n",
    "\n",
    "The code below first validates the counts, displays a sample of the duplicates, and then executes the custom logic to **generate unique, non-colliding IDs** to replace the duplicated indices in `df_tracks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "776a97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate index for tracks: 73\n",
      "number of duplicate index for artists: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Creare un set di tutti gli ID esistenti per un controllo rapido\n",
    "existing_tracks_ids = set(df_tracks.index)\n",
    "existing_artists_ids = set(df_artists.index)\n",
    "\n",
    "# 2. Identificare le posizioni (indice booleano) degli indici duplicati.\n",
    "#    Usiamo keep='first' per segnare solo la seconda, terza, ecc. occorrenza.\n",
    "duplicate_mask_tracks = df_tracks.index.duplicated()\n",
    "duplicate_mask_artists = df_artists.index.duplicated()\n",
    "num_duplicates_tracks = duplicate_mask_tracks.sum()\n",
    "num_duplicates_artists = duplicate_mask_artists.sum()\n",
    "print(\"number of duplicate index for tracks:\", num_duplicates_tracks)\n",
    "print(\"number of duplicate index for artists:\", num_duplicates_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "94ee225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostro tutte le righe che hanno un indice duplicato, ordinate per ID:\n",
      "            id_artist      name_artist  \\\n",
      "id                                       \n",
      "TR108862  ART56320683    Bassi Maestro   \n",
      "TR108862  ART07127070      Noyz Narcos   \n",
      "TR135764  ART73965015           Ghemon   \n",
      "TR135764  ART86549066       Emis Killa   \n",
      "TR190585  ART78209349             Coez   \n",
      "TR190585  ART66932389           Piotta   \n",
      "TR192351  ART81071062        Club Dogo   \n",
      "TR192351  ART88792008    Jake La Furia   \n",
      "TR205970  ART80977821  Jack The Smoker   \n",
      "TR205970  ART08456301          Rancore   \n",
      "\n",
      "                                                 full_title  \\\n",
      "id                                                            \n",
      "TR108862                         Sushi Bar by¬†Bassi¬†Maestro   \n",
      "TR108862                    SPINE by¬†Noyz¬†Narcos (Ft.¬†Coez)   \n",
      "TR135764                   Nessuno vale quanto te by¬†Ghemon   \n",
      "TR135764          Giovani eroi by¬†Emis¬†Killa (Ft.¬†Not¬†Good)   \n",
      "TR190585     Nei treni la notte by¬†Coez (Ft.¬†Frah¬†Quintale)   \n",
      "TR190585                Serpico by¬†Piotta (Ft.¬†Tiromancino)   \n",
      "TR192351        Torner√≤ Da Re - Redrum Version by¬†Club¬†Dogo   \n",
      "TR192351                Musica Commerciale by¬†Jake¬†La Furia   \n",
      "TR205970  24.7 by¬†Jack¬†The Smoker (Ft.¬†Bassi¬†Maestro & Gu√®)   \n",
      "TR205970               Sigla Catteland by¬†Rancore & DJ¬†Myke   \n",
      "\n",
      "                                   title    featured_artists   primary_artist  \\\n",
      "id                                                                              \n",
      "TR108862                       Sushi Bar                <NA>    Bassi Maestro   \n",
      "TR108862                           SPINE                Coez      Noyz Narcos   \n",
      "TR135764          Nessuno vale quanto te                <NA>           Ghemon   \n",
      "TR135764                    Giovani eroi            Not Good       Emis Killa   \n",
      "TR190585              Nei treni la notte       Frah Quintale             Coez   \n",
      "TR190585                         Serpico         Tiromancino           Piotta   \n",
      "TR192351  Torner√≤ Da Re - Redrum Version                <NA>        Club Dogo   \n",
      "TR192351              Musica Commerciale                <NA>    Jake La Furia   \n",
      "TR205970                            24.7  Bassi Maestro, Gu√®  Jack The Smoker   \n",
      "TR205970                 Sigla Catteland                <NA>          Rancore   \n",
      "\n",
      "         language                              album  stats_pageviews  \\\n",
      "id                                                                      \n",
      "TR108862       en                           Sushi EP              NaN   \n",
      "TR108862       cs                     VIRUS (Deluxe)          19050.0   \n",
      "TR135764       it                           ORCHIdee           7182.0   \n",
      "TR135764       it                 Keta Music, Vol. 3          13155.0   \n",
      "TR190585       it                 From The Rooftop 2              NaN   \n",
      "TR190585       pl                   ‚Äôna notte infame              NaN   \n",
      "TR192351       it     Vile Denaro - 10th Anniversary              NaN   \n",
      "TR192351       it  Musica Commerciale Deluxe Edition          10684.0   \n",
      "TR205970       it                              V.Ita              NaN   \n",
      "TR205970       it                               <NA>              NaN   \n",
      "\n",
      "          swear_IT  swear_EN                                 swear_IT_words  \\\n",
      "id                                                                            \n",
      "TR108862         8         1          [bastardo, cesso, culo, fesso, merda]   \n",
      "TR108862         1         0                                      [scopare]   \n",
      "TR135764         0         0                                             []   \n",
      "TR135764         5         1                [bastardo, cazzo, merda, troia]   \n",
      "TR190585         0         0                                             []   \n",
      "TR190585         0         0                                             []   \n",
      "TR192351         1         0                                         [culo]   \n",
      "TR192351         8         0  [cagare, cazzo, culo, figo, incazzare, merda]   \n",
      "TR205970         4         0                                  [figa, merda]   \n",
      "TR205970         0         0                                             []   \n",
      "\n",
      "         swear_EN_words    year  month   day  n_sentences  n_tokens  \\\n",
      "id                                                                    \n",
      "TR108862     [bastardo]  2007.0   11.0  13.0         67.0     610.0   \n",
      "TR108862             []  1932.0    1.0  14.0         36.0     306.0   \n",
      "TR135764             []  2068.0    5.0  27.0         72.0     466.0   \n",
      "TR135764     [bastardo]  2021.0    7.0  23.0         52.0     584.0   \n",
      "TR190585             []  2022.0   10.0  14.0         44.0     295.0   \n",
      "TR190585             []  2024.0    3.0   1.0         69.0     488.0   \n",
      "TR192351             []  2017.0    5.0  19.0         86.0     683.0   \n",
      "TR192351             []  2013.0   10.0  29.0         36.0     534.0   \n",
      "TR205970             []  1910.0   10.0  10.0         48.0     490.0   \n",
      "TR205970             []  2013.0    NaN   NaN         20.0     148.0   \n",
      "\n",
      "          tokens_per_sent  char_per_tok  lexical_density  \\\n",
      "id                                                         \n",
      "TR108862         9.104478      3.707980         0.490662   \n",
      "TR108862         8.500000      3.806691         0.542751   \n",
      "TR135764         6.472222      4.305687         0.473934   \n",
      "TR135764        11.230769      3.889558         0.487952   \n",
      "TR190585         6.704545      4.256140         0.498246   \n",
      "TR190585         7.072464      4.042254         0.530516   \n",
      "TR192351         7.941860      3.748103         0.449165   \n",
      "TR192351        14.833333      3.880503         0.496855   \n",
      "TR205970        10.208333      3.733766         0.465368   \n",
      "TR205970         7.400000      4.574627         0.537313   \n",
      "\n",
      "          avg_token_per_clause     bpm  centroid    rolloff    flux     rms  \\\n",
      "id                                                                            \n",
      "TR108862              5.922330   89.98    0.1302  1262.0061  1.4183  0.1970   \n",
      "TR108862              6.120000   84.97    0.1069  1307.9852  1.1196  0.2700   \n",
      "TR135764              6.383562   92.05    0.1355  1222.7497  1.1038  0.2144   \n",
      "TR135764              7.121951  165.58    0.1434  1286.8483  1.3029  0.3015   \n",
      "TR190585              6.704545  135.20    0.1077  1099.6117  0.9851  0.1700   \n",
      "TR190585              7.176471   91.96    0.1360  1091.7072  1.1547  0.2306   \n",
      "TR192351              5.598361   83.97    0.2028  1803.5711  1.3480  0.2932   \n",
      "TR192351              5.621053  128.19    0.1353  1436.6329  1.3272  0.2598   \n",
      "TR205970              6.282051   86.06    0.1573  1764.7418  1.2966  0.2984   \n",
      "TR205970              6.727273   98.03    0.1513  1809.8772  1.1953  0.2594   \n",
      "\n",
      "             zcr  flatness  spectral_complexity      pitch  loudness  \\\n",
      "id                                                                     \n",
      "TR108862  0.0527    0.9319              22.1130  2356.4160   20.0195   \n",
      "TR108862  0.0524    0.9056              29.6680  2132.3250   30.8700   \n",
      "TR135764  0.0568    0.9251              28.2788  1896.4159   22.2053   \n",
      "TR135764  0.0564    0.9067              35.7936  2132.3474   34.1819   \n",
      "TR190585  0.0447    0.8918              17.3859  1709.2517   16.3989   \n",
      "TR190585  0.0508    0.9327              23.5366  2503.3810   24.9774   \n",
      "TR192351  0.0721    0.8205              24.8264  2876.5173   33.8417   \n",
      "TR192351  0.0574    0.8673              30.2980  2236.3089   29.5758   \n",
      "TR205970  0.0697    0.9016              40.1808  2170.3874   33.8672   \n",
      "TR205970  0.0718    0.8230              42.1591  2191.6551   28.7624   \n",
      "\n",
      "                            album_name album_release_date album_type  \\\n",
      "id                                                                     \n",
      "TR108862                    Sushi - EP         2007-11-13     single   \n",
      "TR108862                         VIRUS         2022-01-14      album   \n",
      "TR135764                      ORCHIdee         2014-05-27      album   \n",
      "TR135764            Keta Music, Vol. 3         2021-07-23      album   \n",
      "TR190585            From The Rooftop 2         2022-10-14      album   \n",
      "TR190585              'na notte infame         2024-03-01      album   \n",
      "TR192351  Vile Denaro 10th Anniversary         2007-05-17      album   \n",
      "TR192351            Musica Commerciale         2013-01-01      album   \n",
      "TR205970                         V.Ita         2009-10-10      album   \n",
      "TR205970            Musica per bambini         2018-06-01      album   \n",
      "\n",
      "          disc_number  track_number  duration_ms  explicit  popularity  \\\n",
      "id                                                                       \n",
      "TR108862            1             3     215461.0      True         6.0   \n",
      "TR108862            1             6     155294.0      True        44.0   \n",
      "TR135764            1             8     238773.0     False        26.0   \n",
      "TR135764            1            10     152733.0      True        35.0   \n",
      "TR190585            1             3     181789.0     False        43.0   \n",
      "TR190585            1             2     192994.0     False        21.0   \n",
      "TR192351            2             4     244226.0     False         9.0   \n",
      "TR192351            1             1     163517.0     False        39.0   \n",
      "TR205970            1             6     240053.0      True        13.0   \n",
      "TR205970            1             8     279213.0     False        42.0   \n",
      "\n",
      "                                                album_image   id_album  \\\n",
      "id                                                                       \n",
      "TR108862  https://i.scdn.co/image/ab67616d0000b2734311be...  ALB697589   \n",
      "TR108862  https://i.scdn.co/image/ab67616d0000b273cad459...  ALB525038   \n",
      "TR135764  https://i.scdn.co/image/ab67616d0000b273f7338f...  ALB346809   \n",
      "TR135764  https://i.scdn.co/image/ab67616d0000b27361a8db...  ALB168242   \n",
      "TR190585  https://i.scdn.co/image/ab67616d0000b273f4c5be...  ALB760031   \n",
      "TR190585  https://i.scdn.co/image/ab67616d0000b2735e9652...  ALB996374   \n",
      "TR192351  https://i.scdn.co/image/ab67616d0000b27357cfe6...  ALB390480   \n",
      "TR192351  https://i.scdn.co/image/ab67616d0000b273d49501...  ALB145179   \n",
      "TR205970  https://i.scdn.co/image/ab67616d0000b273418414...  ALB704296   \n",
      "TR205970  https://i.scdn.co/image/ab67616d0000b2736545b2...  ALB599065   \n",
      "\n",
      "                                                     lyrics  \\\n",
      "id                                                            \n",
      "TR108862  Questo mondo resta freddo anche se vivi da sta...   \n",
      "TR108862  Sei al centro del mio cuore come 'na spina\\nSe...   \n",
      "TR135764  Dicono che da un posto piccolo non pu√≤ venire ...   \n",
      "TR135764  Oh, la city √® silenziosa, in zona solo un clac...   \n",
      "TR190585  Ho fatto un giro in questa citt√†\\nEd √® come fa...   \n",
      "TR190585  Se c'avessi diciott'anni\\nCo quer fuoco che c'...   \n",
      "TR192351  Quando ritorner√≤ da te\\nIo ci ritorner√≤ da re\\...   \n",
      "TR192351  Permettete una parola che √® da un po' che ho n...   \n",
      "TR205970  Vivo questa roba, scrivo della merda che ti sv...   \n",
      "TR205970  Stai su Deejay, su Radio Deejay\\nQuesto √® un a...   \n",
      "\n",
      "          modified_popularity  \n",
      "id                             \n",
      "TR108862                False  \n",
      "TR108862                False  \n",
      "TR135764                False  \n",
      "TR135764                False  \n",
      "TR190585                False  \n",
      "TR190585                False  \n",
      "TR192351                False  \n",
      "TR192351                False  \n",
      "TR205970                False  \n",
      "TR205970                False  \n"
     ]
    }
   ],
   "source": [
    "# 1. Creare una maschera per identificare TUTTE le righe (inclusa la prima)\n",
    "#    che hanno un indice duplicato.\n",
    "all_duplicates_mask = df_tracks.index.duplicated(keep=False)\n",
    "\n",
    "# 2. Filtrare il DataFrame per ottenere solo queste righe\n",
    "df_duplicate_groups = df_tracks[all_duplicates_mask]\n",
    "\n",
    "# 3. Ordinare per indice. Questo √® fondamentale per vedere\n",
    "#    le righe con lo stesso indice una accanto all'altra.\n",
    "df_duplicate_groups_sorted = df_duplicate_groups.sort_index()\n",
    "\n",
    "# 4. Stampare i gruppi di duplicati\n",
    "if not df_duplicate_groups_sorted.empty:\n",
    "    print(\"Mostro tutte le righe che hanno un indice duplicato, ordinate per ID:\")\n",
    "    # Stampiamo le prime 30 (o modifica il numero se vuoi vederne di pi√π)\n",
    "    print(df_duplicate_groups_sorted.head(10))\n",
    "else:\n",
    "    # Questo scenario si verifica se num_duplicates (dal tuo codice) era 0\n",
    "    print(\"Nessuna riga con indice duplicato trovata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "6970c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Generating 73 random unique IDs...\n",
      "Finished generating unique IDs.\n",
      "\n",
      "Generated 73 new unique IDs.\n",
      "Example new ID: TR715149\n",
      "Check for duplicates after replacement: False\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# --- 1. Identify Duplicated Rows and Count ---\n",
    "# Find the boolean mask for rows where the ID (index) is duplicated,\n",
    "# keeping only the duplicates *after* the first occurrence.\n",
    "duplicated_mask = df_tracks.index.duplicated(keep='first')\n",
    "num_duplicates_to_replace = duplicated_mask.sum() # Should be 73\n",
    "print(num_duplicates_to_replace)\n",
    "\n",
    "# --- 2. Define ID Generation Helper ---\n",
    "def format_track_id(number, prefix='TR', padding=6):\n",
    "    \"\"\"Formats a number into a TRXXXXXX string.\"\"\"\n",
    "    # Uses f-string formatting to zero-pad the number to 6 digits\n",
    "    return f\"{prefix}{number:0{padding}d}\"\n",
    "\n",
    "# --- 3. Generate New Unique IDs with Collision Check ---\n",
    "\n",
    "# Convert the existing index to a set for O(1) average time complexity lookups\n",
    "existing_ids = set(df_tracks.index)\n",
    "new_track_ids = []\n",
    "\n",
    "# Range for 6-digit numbers (000000 to 999999)\n",
    "MIN_ID = 0\n",
    "MAX_ID = 999999 \n",
    "\n",
    "print(f\"Generating {num_duplicates_to_replace} random unique IDs...\")\n",
    "\n",
    "while len(new_track_ids) < num_duplicates_to_replace:\n",
    "    # Generate a random 6-digit number\n",
    "    random_num = random.randint(MIN_ID, MAX_ID)\n",
    "    \n",
    "    # Format it to the \"TRXXXXXX\" string\n",
    "    new_id = format_track_id(random_num)\n",
    "    \n",
    "    # Check for collision against all existing IDs\n",
    "    if new_id not in existing_ids:\n",
    "        new_track_ids.append(new_id)\n",
    "        # Immediately add the new ID to the existing_ids set to prevent\n",
    "        # generating the same random ID twice during this loop\n",
    "        existing_ids.add(new_id)\n",
    "\n",
    "print(\"Finished generating unique IDs.\")\n",
    "\n",
    "# --- 4. Replace Duplicated IDs in the DataFrame Index ---\n",
    "\n",
    "# Get the actual index values that need to be replaced (the index values of the duplicated rows)\n",
    "indices_to_replace = df_tracks.index[duplicated_mask]\n",
    "\n",
    "# Create a Series of the new IDs, matching the indices (positions) of the duplicated rows\n",
    "new_ids_series = pd.Series(\n",
    "    new_track_ids,\n",
    "    index=indices_to_replace\n",
    ")\n",
    "\n",
    "# Replace the duplicated index values in-place\n",
    "df_tracks.index.values[duplicated_mask] = new_ids_series.values\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"\\nGenerated {len(new_track_ids)} new unique IDs.\")\n",
    "print(f\"Example new ID: {new_track_ids[0]}\")\n",
    "print(f\"Check for duplicates after replacement: {df_tracks.index.duplicated().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2032d",
   "metadata": {},
   "source": [
    "## üßπ Removing Redundant Artist Columns\n",
    "\n",
    "We discovered that **`name_artist`**, **`name`**, and **`primary_artist`** all highlight the same information, creating unnecessary redundancy in our dataset. To determine which columns to keep, we performed a thorough **normalization and comparison analysis**.\n",
    "\n",
    "After joining the tracks and artists DataFrames, we implemented a **helper function** to normalize all artist-related string columns. This normalization process includes:\n",
    "- Converting to lowercase\n",
    "- Removing accents (e.g., '√®' ‚Üí 'e')  \n",
    "- Stripping special characters\n",
    "- Trimming whitespace\n",
    "\n",
    "We applied this normalization to **`name`**, **`primary_artist`**, **`name_artist`**, and **`featured_artists`** to ensure a fair comparison. Our analysis revealed that **`primary_artist`** and **`name_artist`** are *identical* after normalization, while **`name`** contains the same unique values but with a slightly altered version for some artists, hence still being redundant.\n",
    "\n",
    "We also checked for **self-titled tracks** (where the track name matches the artist name) and examined edge cases like featured artists. Based on these findings, we confidently **dropped** the redundant **`name`** and **`primary_artist`** columns, retaining only **`name_artist`** as this column (equivalent to **`primary_artist`**) matches the same version of how the artist name is written in **`featured_artists`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "09fbdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tracks.join(df_artists, on='id_artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "91a7e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione helper per la normalizzazione\n",
    "def normalize_series(series):\n",
    "    # 1. Minuscolo\n",
    "    s = series.str.lower()\n",
    "    \n",
    "    # 2. Rimuove accenti (es. '√®' -> 'e')\n",
    "    # NFKD normalizza i caratteri, 'ascii' rimuove ci√≤ che non √® ascii (accenti)\n",
    "    s = s.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "    # 3. Rimuove caratteri speciali (tutto tranne lettere, numeri, spazi)\n",
    "    # [^\\w\\s] significa \"tutto ci√≤ che NON √® un carattere di parola (\\w) o uno spazio (\\s)\"\n",
    "    s = s.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    \n",
    "    # 4. Rimuove spazi extra all'inizio/fine\n",
    "    s = s.str.strip()\n",
    "    \n",
    "    # (Opzionale) Sostituisce spazi multipli con uno singolo\n",
    "    s = s.str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "1f5f1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applichiamo la normalizzazione alle tre colonne\n",
    "df['name'] = normalize_series(df['name'])\n",
    "df['primary_artist'] = normalize_series(df['primary_artist'])\n",
    "df['name_artist'] = normalize_series(df['name_artist'])\n",
    "df['featured_artists'] = normalize_series(df['featured_artists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "03edf8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisi: 'primary_artist' e 'name_artist' sono sempre identici dopo la normalizzazione.\n"
     ]
    }
   ],
   "source": [
    "# Controlla se le due colonne sono SEMPRE identiche\n",
    "are_artists_identical = (df['primary_artist'] == df['name_artist']).all()\n",
    "\n",
    "if are_artists_identical:\n",
    "    print(\"Analisi: 'primary_artist' e 'name_artist' sono sempre identici dopo la normalizzazione.\")\n",
    "else:\n",
    "    print(\"Analisi: 'primary_artist' e 'name_artist' NON sono sempre identici.\")\n",
    "    \n",
    "    diff_df = df[df['primary_artist'] != df['name_artist']]\n",
    "    print(diff_df[['primary_artist', 'name_artist', 'primary_artist', 'name_artist']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "fd05ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name primary_artist\n",
      "id                                   \n",
      "TR317207   gue pequeno            gue\n",
      "TR446826   gue pequeno            gue\n",
      "TR228275   gue pequeno            gue\n",
      "TR697556   gue pequeno            gue\n",
      "TR391415   gue pequeno            gue\n",
      "...                ...            ...\n",
      "TR794750  samuel heron   samuel costa\n",
      "TR102539  samuel heron   samuel costa\n",
      "TR178809   joey funboy       joey ita\n",
      "TR589443   joey funboy       joey ita\n",
      "TR735987   joey funboy       joey ita\n",
      "\n",
      "[870 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cerca tracce omonime (dove il nome della traccia √® uguale al nome dell'artista)\n",
    "self_titled_tracks = df[df['name'] != df['primary_artist']]\n",
    "print(self_titled_tracks[['name', 'primary_artist']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "7cf3beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['name', 'primary_artist'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fbd38",
   "metadata": {},
   "source": [
    "Active_end column is completely empty so we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "2707cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['active_end'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f54aac",
   "metadata": {},
   "source": [
    "## üîç Analyzing `full_title`\n",
    "\n",
    "### `full_title` vs `title` Redundancy\n",
    "\n",
    "The **`full_title`** and **`title`** attributes should theoretically correspond, as both identify the track's name. However, **`full_title`** contains additional information by appending the performer with **\"by (artist_name)\"** and featuring artists with **\"Ft. (featured_artists)\"**.\n",
    "\n",
    "This explains why **`full_title`** has more unique values compared to **`title`**. However, by examining the actual title name contained in the first portion of **`full_title`**, we notice that the two columns do in fact correspond to the same underlying track name.\n",
    "\n",
    "We performed a **regex-based extraction and normalization** to verify this relationship holds across *all* records. The process involved:\n",
    "\n",
    "- **Extracting** the title portion from **`full_title`** by splitting at the last occurrence of `\" by\"`\n",
    "- **Normalizing smart quotes and apostrophes** (e.g., `'` ‚Üí `'`, `\"` ‚Üí `\"`) to handle encoding differences\n",
    "- **Standardizing whitespace** by stripping leading/trailing spaces and collapsing multiple spaces into one\n",
    "\n",
    "After these comprehensive normalization steps, we confirmed that the extracted title from **`full_title`** is *identical* to **`title`** across all rows. This allows us to confidently **discard** one of the two columns, eliminating redundancy while preserving complete information.\n",
    "\n",
    "This verification ensures data integrity and simplifies our schema for future analysis. ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "66840002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(series):\n",
    "    \"\"\"\n",
    "    Normalize a pandas Series containing titles by:\n",
    "    - Replacing smart quotes/apostrophes with straight ones\n",
    "    - Stripping leading/trailing whitespace\n",
    "    - Collapsing multiple spaces into single spaces\n",
    "    \"\"\"\n",
    "    # Normalize smart apostrophes\n",
    "    s = series.str.replace('‚Äô', \"'\", regex=False)\n",
    "    s = s.str.replace('‚Äò', \"'\", regex=False)\n",
    "\n",
    "    # Normalize smart double quotes\n",
    "    s = s.str.replace('‚Äú', '\"', regex=False)\n",
    "    s = s.str.replace('‚Äù', '\"', regex=False)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    s = s.str.strip()\n",
    "    s = s.str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2af45c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the columns equal after normalization? True\n",
      "Number of rows still unequal: 0\n"
     ]
    }
   ],
   "source": [
    "df_title = df_tracks[['full_title', 'title']].copy()\n",
    "\n",
    "# Extract title portion from full_title\n",
    "split_series = df_title['full_title'].str.rsplit(' by', n=1)\n",
    "df_title['cleaned_attribute'] = split_series.str[0]\n",
    "\n",
    "# Apply normalization to both columns\n",
    "df_title['cleaned_attribute'] = normalize_title(df_title['cleaned_attribute'])\n",
    "df_title['title'] = normalize_title(df_title['title'])\n",
    "\n",
    "# Compare results\n",
    "are_columns_equal_final = (df_title['cleaned_attribute'] == df_title['title']).all()\n",
    "print(f\"Are the columns equal after normalization? {are_columns_equal_final}\")\n",
    "\n",
    "# Check the remaining mismatched rows (should now be 0)\n",
    "final_mismatched_rows = df_title[df_title['cleaned_attribute'] != df_title['title']]\n",
    "print(f\"Number of rows still unequal: {len(final_mismatched_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ec2c7",
   "metadata": {},
   "source": [
    "## üéµ Validating Artist and Featured Artists from `full_title`\n",
    "\n",
    "Having established that **`full_title`** contains redundant information about track titles, we now investigate whether the **artist** and **featured artists** information embedded in **`full_title`** matches the dedicated columns **`name_artist`** and **`featured_artists`**.\n",
    "\n",
    "The **`full_title`** follows the pattern: `\"Track Name by Artist (Ft. Featured Artists)\"` or `\"Track Name by Artist, Featured Artist 1, ... & Featured Artist N\"`. We perform a **multi-step extraction and normalization** process to validate this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "d6cb61aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the artist names equal? True\n",
      "Number of rows still unequal: 0\n"
     ]
    }
   ],
   "source": [
    "df_artist_and_feat = df_tracks[['full_title', 'name_artist', 'featured_artists']].copy()\n",
    "\n",
    "df_artist_and_feat['name_artist'] = normalize_title(df_artist_and_feat['name_artist'])\n",
    "df_artist_and_feat['featured_artists'] = normalize_title(df_artist_and_feat['featured_artists'])\n",
    "df_artist_and_feat['full_title'] = normalize_title(df_artist_and_feat['full_title'])\n",
    "\n",
    "# --- Step 1: Extract 'artist_and_feat' (Artist + Features) ---\n",
    "split_series_1 = df_artist_and_feat['full_title'].str.rsplit(' by', n=1)\n",
    "df_artist_and_feat['artist_and_feat'] = split_series_1.str[1]\n",
    "df_artist_and_feat.drop(columns=['full_title'], inplace=True)\n",
    "\n",
    "# --- Step 2: Separate 'cleaned_artist' from 'cleaned_feat' ---\n",
    "split_series_2 = df_artist_and_feat['artist_and_feat'].str.rsplit('(Ft.', n=1)\n",
    "df_artist_and_feat['cleaned_artist'] = split_series_2.str[0]\n",
    "df_artist_and_feat['cleaned_feat'] = split_series_2.str[1].str.replace(r'\\)$', '', regex=True)\n",
    "\n",
    "# --- NEW: Convert & to , BEFORE extracting the artist ---\n",
    "df_artist_and_feat['cleaned_artist'] = df_artist_and_feat['cleaned_artist'].str.replace('&', ',', regex=False)\n",
    "\n",
    "# --- Extract primary artist by splitting at the FIRST comma ---\n",
    "split_series_3 = df_artist_and_feat['cleaned_artist'].str.split(',', n=1)\n",
    "df_artist_and_feat['cleaned_artist'] = split_series_3.str[0]\n",
    "\n",
    "# The remaining artists after the first comma become features\n",
    "remaining_artists = split_series_3.str[1]\n",
    "\n",
    "# --- Move remaining artists to 'cleaned_feat' if '(Ft....)' was empty ---\n",
    "mask_empty_feat = df_artist_and_feat['cleaned_feat'].isna() | (df_artist_and_feat['cleaned_feat'].str.strip() == '')\n",
    "\n",
    "df_artist_and_feat['cleaned_feat'] = df_artist_and_feat['cleaned_feat'].mask(\n",
    "    mask_empty_feat,\n",
    "    remaining_artists.fillna('').str.strip()\n",
    ")\n",
    "\n",
    "# --- Strip whitespace from cleaned_artist ---\n",
    "df_artist_and_feat['cleaned_artist'] = df_artist_and_feat['cleaned_artist'].str.strip()\n",
    "\n",
    "# --- Final Comparison ---\n",
    "are_names_equal_final = (df_artist_and_feat['cleaned_artist'] == df_artist_and_feat['name_artist']).all()\n",
    "print(f\"Are the artist names equal? {are_names_equal_final}\")\n",
    "\n",
    "# Identify and print the remaining mismatched rows\n",
    "final_mismatched_rows = df_artist_and_feat[df_artist_and_feat['cleaned_artist'] != df_artist_and_feat['name_artist']]\n",
    "print(f\"Number of rows still unequal: {len(final_mismatched_rows)}\")\n",
    "\n",
    "# if len(final_mismatched_rows) > 0:\n",
    "#     print(\"\\nSample of remaining mismatched rows:\")\n",
    "#     rows_to_display = final_mismatched_rows.head(10)\n",
    "#     print(rows_to_display[['name_artist', 'cleaned_artist']])\n",
    "    \n",
    "#     print(\"\\nFirst Mismatched Row Details:\")\n",
    "#     first_id = rows_to_display.index[0]\n",
    "#     print(f\"name_artist: '{df_artist_and_feat['name_artist'].loc[first_id]}'\")\n",
    "#     print(f\"cleaned_artist: '{df_artist_and_feat['cleaned_artist'].loc[first_id]}'\")\n",
    "\n",
    "# df_artist_and_feat.drop(columns=['artist_and_feat'], inplace=True)\n",
    "# print(df_artist_and_feat[['name_artist', 'cleaned_artist']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee95500",
   "metadata": {},
   "source": [
    "After applying comprehensive normalization to compare **`cleaned_feat`** (extracted from **`full_title`**) with the original **`featured_artists`** column, we identified **413 mismatched rows**.\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "The mismatches reveal a systematic pattern: in many cases, the original **`featured_artists`** column is *empty* while **`cleaned_feat`** contains valid artist names extracted from **`full_title`**. This indicates that **`full_title`** actually contains *more complete* information about featured artists than the dedicated **`featured_artists`** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "51dfbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_artists(series):\n",
    "    \"\"\"\n",
    "    Normalize and sort a pandas Series containing artist names by:\n",
    "    - Replacing '&' with ',' for consistent delimiter\n",
    "    - Splitting by comma into individual artists\n",
    "    - Stripping whitespace from each artist name\n",
    "    - Sorting artists alphabetically\n",
    "    - Rejoining into a single comma-separated string\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        A pandas Series containing artist names (can be comma or ampersand-separated)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series\n",
    "        A normalized Series with alphabetically sorted, comma-separated artist names\n",
    "    \"\"\"\n",
    "    # Replace & with , for consistent delimiter\n",
    "    s = series.str.replace('&', ',', regex=False)\n",
    "    \n",
    "    # Split by comma, strip whitespace, and filter out empty strings\n",
    "    list_artists = s.str.split(',').apply(\n",
    "        lambda x: [item.strip() for item in x if item.strip()] if isinstance(x, list) else []\n",
    "    )\n",
    "    \n",
    "    # Sort alphabetically\n",
    "    sorted_artists = list_artists.apply(lambda x: sorted(x))\n",
    "    \n",
    "    # Rejoin into comma-separated string\n",
    "    normalized_series = sorted_artists.apply(lambda x: ', '.join(x))\n",
    "    \n",
    "    return normalized_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "cdcf3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows still unequal: 413\n",
      "\n",
      "Sample of remaining mismatched rows:\n",
      "         featured_artists                                       cleaned_feat\n",
      "id                                                                          \n",
      "TR266736                   Friman (ITA), Mehdi (ITA), Mothz, Spender, The...\n",
      "TR281032                                                           Manu Chao\n",
      "TR811171                                                         Mara Sattei\n",
      "TR822203                                                         Mara Sattei\n",
      "TR397308                                                       Tiziano Ferro\n",
      "TR212338                                                         Mara Sattei\n",
      "TR372774                                                         Mara Sattei\n",
      "TR993112                                                         Mara Sattei\n",
      "TR444969                                                         Mara Sattei\n",
      "TR479694                                                         Mara Sattei\n",
      "\n",
      "Cleaned Series for First Mismatched Row (After Aggressive Strip):\n",
      "featured_artists (normalized): ''\n",
      "cleaned_feat (normalized): 'Friman (ITA), Mehdi (ITA), Mothz, Spender, Thelonious B., Zyrtck'\n"
     ]
    }
   ],
   "source": [
    "df_artist_and_feat['featured_artists'] = sort_artists(df_artist_and_feat['featured_artists'])\n",
    "df_artist_and_feat['cleaned_feat'] = sort_artists(df_artist_and_feat['cleaned_feat'])\n",
    "\n",
    "# Identify and print the remaining mismatched rows using the normalized series\n",
    "final_mismatched_rows = df_artist_and_feat[df_artist_and_feat['cleaned_feat'] != df_artist_and_feat['featured_artists']]\n",
    "print(f\"Number of rows still unequal: {len(final_mismatched_rows)}\")\n",
    "\n",
    "# Print the remaining mismatched rows for inspection\n",
    "if len(final_mismatched_rows) > 0:\n",
    "    print(\"\\nSample of remaining mismatched rows:\")\n",
    "    # We display the original columns and the two normalized versions for true inspection\n",
    "    rows_to_display = final_mismatched_rows.head(10)\n",
    "    print(rows_to_display[['featured_artists', 'cleaned_feat']])\n",
    "\n",
    "    print(\"\\nCleaned Series for First Mismatched Row (After Aggressive Strip):\")\n",
    "    first_id = rows_to_display.index[0]\n",
    "    # Use the normalized series for the clearest inspection\n",
    "    print(f\"featured_artists (normalized): '{df_artist_and_feat['featured_artists'].loc[first_id]}'\")\n",
    "    print(f\"cleaned_feat (normalized): '{df_artist_and_feat['cleaned_feat'].loc[first_id]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd5e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "TR934808             [Ernia, Gu√®]\n",
      "TR760029          [Thelonious B.]\n",
      "TR916821    [MamboLosco, RADICAL]\n",
      "TR480968                 [Taxi B]\n",
      "TR585039                  [Rkomi]\n",
      "Name: featured_artists, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['featured_artists'] = df_artist_and_feat['cleaned_feat']\n",
    "\n",
    "df['featured_artists'] = df['featured_artists'].apply(\n",
    "    lambda x: [] if pd.isna(x) else [s.strip() for s in x.split(',')]\n",
    ")\n",
    "\n",
    "df['featured_artists'] = df['featured_artists'].apply(\n",
    "    lambda lst: [normalize_series(x) for x in lst]\n",
    ")\n",
    "\n",
    "print(df['featured_artists'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "422c9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for featured_artist in df['featured_artists']\n",
    "# df['featured_artists'] = normalize_series(df_artist_and_feat['cleaned_feat'])\n",
    "# print(df['featured_artists'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceccbd6a",
   "metadata": {},
   "source": [
    "Now full title column is redundant: the featured artist has been extracted and the title column is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "6ffdbd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['full_title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77086400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "9baa21a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "TR934808             [Ernia, Gu√®]\n",
      "TR760029          [Thelonious B.]\n",
      "TR916821    [MamboLosco, RADICAL]\n",
      "TR480968                 [Taxi B]\n",
      "TR585039                  [Rkomi]\n",
      "TR550335                       []\n",
      "TR170793                       []\n",
      "TR627195              [Dani Faiv]\n",
      "TR628871                       []\n",
      "TR700756                       []\n",
      "Name: featured_artists, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['featured_artists'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f6ea7",
   "metadata": {},
   "source": [
    "## Language attribute\n",
    "Most present language for main lyrics are italian. english and polish. We checked most of these languages and they don't seem to respect the main language of the lyrics.\n",
    "\n",
    "So we decided to run a SOTA language model to detect based on the tokens of he lyrics colmn the language of the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "74805d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "TR934808    Opl√†, ah\\nBdope, chiama due b\\n\\nMi candiderei...\n",
      "TR760029    Greg Willen, non dormire\\nBrrpoh\\n\\nTTTroppi c...\n",
      "TR916821    Mothz\\nYeah, yeah, yeahyeah\\nBdope, chiama due...\n",
      "TR480968    Designer sui vestiti penso di essere un outlet...\n",
      "TR585039    Bdope Yeah\\n\\nVuole solo me, non fare la gelos...\n",
      "Name: lyrics_normalized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import regex as re  \n",
    "\n",
    "df_language = df_tracks[['language', 'lyrics', 'n_sentences']].copy()\n",
    "\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    # Normalize smart quotes to straight quotes\n",
    "    text = re.sub(r'[‚Äò‚Äô]', \"'\", str(text))\n",
    "    text = re.sub(r'[‚Äú‚Äù]', '\"', text)\n",
    "    # Aggressively remove characters that might be noise or confuse the model (e.g., emojis, non-standard symbols)\n",
    "    text = re.sub(r'[^\\w\\s\\.\\,\\'\\\"]', '', text, flags=re.UNICODE)\n",
    "    return text\n",
    "\n",
    "df_language['lyrics_normalized'] = df_language['lyrics'].apply(normalize_text)\n",
    "\n",
    "print(df_language['lyrics_normalized'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "872851d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         language most_probable_language  confidence  n_sentences\n",
      "id                                                               \n",
      "TR934808       pl                   __it    0.964671        102.0\n",
      "TR760029       en                   __it    0.923832         56.0\n",
      "TR916821       en                   __it    0.953723         88.0\n",
      "TR480968       it                   __it    0.963273         37.0\n",
      "TR585039       en                   __it    0.983940         48.0\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'lid.176.bin'\n",
    "\n",
    "model = fasttext.load_model(MODEL_PATH)\n",
    "\n",
    "def detect_language_safe(text, model):\n",
    "    \"\"\"\n",
    "    Safely detects the language and confidence using FastText.\n",
    "    Fortified to handle DataFrame edge cases (NaN, None, short strings).\n",
    "    Returns a tuple (language_code, confidence_score) or (None, 0.0).\n",
    "    \"\"\"\n",
    "    # 1. Explicitly check for NaN/None and ensure string conversion\n",
    "    if pd.isna(text):\n",
    "        return None, 0.0\n",
    "    \n",
    "    # Ensure it's a string and strip whitespace\n",
    "    text_str = str(text).strip()\n",
    "    \n",
    "    # FIX: Remove newline and carriage return characters, as FastText requires a single line\n",
    "    text_str = text_str.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # FastText needs a minimum amount of text (let's keep the minimum length check)\n",
    "    if len(text_str) < 20: \n",
    "        # Optionally log which records were too short\n",
    "        # print(f\"Skipping record due to short length: {text_str[:10]}...\")\n",
    "        return None, 0.0\n",
    "    \n",
    "    try:\n",
    "        # k=1 asks for the single best prediction\n",
    "        predictions = model.predict(text_str, k=1) \n",
    "        \n",
    "        # predictions[0] is the label list: ['label__it']\n",
    "        # predictions[1] is the probability list: [0.99]\n",
    "        label = predictions[0][0].replace('__label', '')\n",
    "        confidence = predictions[1][0]\n",
    "        \n",
    "        return label, confidence\n",
    "    except Exception as e:\n",
    "        # If an exception is still caught, print a detailed message \n",
    "        # to help diagnose the specific content causing the crash.\n",
    "        print(f\"FastText Prediction failed for input starting: '{text_str[:50]}...'\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        return None, 0.0\n",
    "\n",
    "results = df_language['lyrics_normalized'].apply(\n",
    "    lambda x: detect_language_safe(x, model)\n",
    ")\n",
    "\n",
    "# Unpack the Series of tuples into the two new columns\n",
    "\n",
    "# The first element of the tuple is the language code\n",
    "df_language['most_probable_language'] = results.apply(lambda x: x[0])\n",
    "\n",
    "# The second element of the tuple is the confidence score\n",
    "df_language['confidence'] = results.apply(lambda x: x[1])\n",
    "\n",
    "# Displaying the new columns (optional)\n",
    "print(df_language[['language', 'most_probable_language', 'confidence', 'n_sentences']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "d044cc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "__it    10876\n",
      "__en      206\n",
      "__es       52\n",
      "__fr       11\n",
      "__de        5\n",
      "__pt        3\n",
      "__ro        3\n",
      "__mt        1\n",
      "__ja        1\n",
      "__ru        1\n",
      "__bg        1\n",
      "__ar        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Assuming df_language is your DataFrame with the 'confidence' column\n",
    "\n",
    "# Import the necessary plotting library for display\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "collapse_map = {\n",
    "    '__it': '__it',\n",
    "    '__en': '__en',\n",
    "    '__es': '__es',\n",
    "    '__fr': '__fr',\n",
    "    '__de': '__de',\n",
    "    '__pt': '__pt',\n",
    "    '__ro': '__ro',\n",
    "    '__ru': '__ru',\n",
    "    '__bg': '__bg',\n",
    "    '__ar': '__ar',\n",
    "    '__ja': '__ja',\n",
    "    '__mt': '__mt',\n",
    "\n",
    "    # Map regional languages to parent languages:\n",
    "    '__nap': '__it',   # Neapolitan ‚Üí Italian\n",
    "    '__lmo': '__it',   # Lombard ‚Üí Italian\n",
    "    '__ca': '__es',    # Catalan ‚Üí Spanish (if you prefer otherwise, tell me)\n",
    "    '__li': '__de',    # Limburgish ‚Üí German family (closest parent)\n",
    "}\n",
    "\n",
    "df_language['language_main'] = df_language['most_probable_language'].map(collapse_map)\n",
    "df['language'] = df_language['language_main']\n",
    "\n",
    "df['language'].hist(\n",
    "    bins=20, # Number of bins (intervals) for the histogram\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title('Distribution of FastText predicted languages')\n",
    "plt.xlabel('Predicted Language')\n",
    "plt.ylabel('Number of Records (Frequency)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(df['language'].value_counts())\n",
    "# df['language'] = df_language['most_probable_language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "9a54d042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows/values that contain 1 or fewer sentences is: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65069/1835569498.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df_1_sentence, linguistic_columns] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the boolean mask\n",
    "df_1_sentence = df['n_sentences'] <= 1\n",
    "\n",
    "# 2. Count the rows being affected (Correct use of sum())\n",
    "rows_to_nullify = df_1_sentence.sum()\n",
    "print(f\"The number of rows/values that contain 1 or fewer sentences is: {rows_to_nullify}\")\n",
    "\n",
    "# 3. Define the columns to nullify\n",
    "linguistic_columns = ['language', 'swear_IT', 'swear_EN', \n",
    "                      'swear IT words', 'swear_EN_words', 'n_sentences', \n",
    "                      'n_tokens', 'tokens_per_sent', 'avg_token_per_clause', \n",
    "                      'explicit', 'lyrics']\n",
    "\n",
    "# 4. Apply the mask to the DataFrame df (This is the correct operation)\n",
    "df.loc[df_1_sentence, linguistic_columns] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacee0b",
   "metadata": {},
   "source": [
    "## album, album_name, album id\n",
    "\n",
    "While the column album seems more reasonable and coherent, it contains multiple null values.\n",
    "Some album in \"album_name\" appear truncated and incomplete.\n",
    "\n",
    "We decided to keep the normalization for better readability and to have normalized occurrences.\n",
    "\n",
    "To create a new correct version of the column showing the album relative to every tracks we decided to do 3 major choices:\n",
    "\n",
    "    #Choice 1 (for null 'album'): Use 'album_name_norm',\n",
    "    \n",
    "    #Choice 2 (for Mismatch): Use 'album_norm',\n",
    "    \n",
    "    #Choice 3 (for Match): mantain 'album_norm' (the same with 'album_name_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "610103db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creazione di 'correct_album' ---\n",
      "Colonna 'correct_album' creata con successo.\n",
      "\n",
      "--- [FASE 3]: Assegnazione di 'id_album_final' (Algoritmo 1-a-1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65069/851805109.py:38: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  track_counts = df_candidates.groupby(['correct_album', 'id_album']).size().to_frame('count')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio processamento di 1884 album per assegnazione ID...\n",
      "Processamento ID terminato. Mappa 1-a-1 creata.\n",
      "\n",
      "--- VERIFICA FINALE ---\n",
      "Album con pi√π di 1 ID: 0\n",
      "ID con pi√π di 1 Album: 0\n",
      "\n",
      "--- Esempio di 10 righe pulite: ---\n",
      "                               correct_album   id_album id_album_final\n",
      "id                                                                    \n",
      "TR703265                            mm vol 2  ALB378902      ALB378902\n",
      "TR918860                              miguel  ALB275787      ALB275787\n",
      "TR266859                          amarammore  ALB384136      ALB384136\n",
      "TR691812                    edgar allan flow  ALB443954      ALB443954\n",
      "TR586015                    mi ferma nessuno  ALB789185      ALB789185\n",
      "TR719913                                yang  ALB730400      ALB176814\n",
      "TR221903                        habemus capa  ALB548549      ALB548549\n",
      "TR282711                hellvisback platinum  ALB776897      ALB776897\n",
      "TR242186                        lamore e qui  ALB321855      ALB321855\n",
      "TR842497  fastlife mixtape vol 2 faster life  ALB767259      ALB203162\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print(\"--- Creazione di 'correct_album' ---\")\n",
    "\n",
    "# Applica la normalizzazione alle due colonne originali\n",
    "df['album_norm'] = normalize_series(df['album'])\n",
    "df['album_name_norm'] = normalize_series(df['album_name'])\n",
    "\n",
    "# Definisci le condizioni per la colonna 'correct_album'\n",
    "conditions = [\n",
    "    (df['album'].isnull()), # Priorit√† 1: Se 'album' √® nullo...\n",
    "    (df['album_norm'] != df['album_name_norm']), # Priorit√† 2: Se c'√® mismatch...\n",
    "    (df['album_norm'] == df['album_name_norm'])  # Priorit√† 3: Se c'√® match...\n",
    "]\n",
    "\n",
    "# Definisci le scelte corrispondenti\n",
    "choices = [\n",
    "    df['album_name_norm'], # ...usa 'album_name_norm'\n",
    "    df['album_norm'],      # ...usa 'album_norm'\n",
    "    df['album_norm']       # ...usa 'album_norm'\n",
    "]\n",
    "\n",
    "# Crea la colonna 'correct_album'\n",
    "df['correct_album'] = np.select(conditions, choices, default=np.nan)\n",
    "print(\"Colonna 'correct_album' creata con successo.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- [FASE 3]: Assegnazione di 'id_album_final' (Algoritmo 1-a-1) ---\")\n",
    "\n",
    "# --- 3.1: Preparazione ---\n",
    "\n",
    "# Ordina gli album per frequenza (d√† priorit√† agli album pi√π grandi)\n",
    "album_order = df['correct_album'].value_counts().index\n",
    "\n",
    "# Filtra i dati per creare la mappa dei candidati\n",
    "df_candidates = df.dropna(subset=['correct_album', 'id_album'])\n",
    "track_counts = df_candidates.groupby(['correct_album', 'id_album']).size().to_frame('count')\n",
    "\n",
    "# Ordina i candidati per album e poi per frequenza\n",
    "track_counts = track_counts.sort_values(['correct_album', 'count'], ascending=[True, False])\n",
    "\n",
    "# Crea un dizionario di liste di candidati: {'Album': ['id_pi√π_freq', 'id_secondo_pi√π_freq']}\n",
    "all_id_candidates = track_counts.reset_index().groupby('correct_album')['id_album'].apply(list).to_dict()\n",
    "\n",
    "# --- 3.2: Esecuzione del Loop ---\n",
    "\n",
    "used_ids = set() # Set per gli ID gi√† \"presi\"\n",
    "final_album_to_id_map = {} # La nostra mappa pulita finale\n",
    "\n",
    "def generate_new_id():\n",
    "    new_id = f\"ALB{random.randint(100000, 999999)}\"\n",
    "    while new_id in used_ids:\n",
    "        new_id = f\"ALB{random.randint(100000, 999999)}\"\n",
    "    return new_id\n",
    "\n",
    "print(f\"Inizio processamento di {len(album_order)} album per assegnazione ID...\")\n",
    "\n",
    "# Itera sugli album in ordine di priorit√†\n",
    "for album_name in album_order:\n",
    "    \n",
    "    candidate_ids = all_id_candidates.get(album_name, []) # Lista di ID candidati\n",
    "    assigned_id = None # Flag\n",
    "\n",
    "    # Cerca il primo ID valido (non gi√† usato)\n",
    "    for potential_id in candidate_ids:\n",
    "        if potential_id not in used_ids:\n",
    "            assigned_id = potential_id\n",
    "            used_ids.add(assigned_id) # \"Prenota\" l'ID\n",
    "            final_album_to_id_map[album_name] = assigned_id\n",
    "            break # Passa all'album successivo\n",
    "    \n",
    "    # Se non √® stato trovato nessun ID valido (o non c'erano candidati)\n",
    "    if assigned_id is None:\n",
    "        new_id = generate_new_id()\n",
    "        used_ids.add(new_id)\n",
    "        final_album_to_id_map[album_name] = new_id\n",
    "\n",
    "print(\"Processamento ID terminato. Mappa 1-a-1 creata.\")\n",
    "\n",
    "# --- 3.3: Applicazione Finale ---\n",
    "\n",
    "# Applica la mappa pulita al DataFrame\n",
    "df['id_album_final'] = df['correct_album'].map(final_album_to_id_map)\n",
    "\n",
    "print(\"\\n--- VERIFICA FINALE ---\")\n",
    "\n",
    "# Controlla la relazione 1-a-1\n",
    "check_ids_per_album = df.groupby('correct_album')['id_album_final'].nunique()\n",
    "check_albums_per_id = df.groupby('id_album_final')['correct_album'].nunique()\n",
    "\n",
    "print(f\"Album con pi√π di 1 ID: {(check_ids_per_album > 1).sum()}\")\n",
    "print(f\"ID con pi√π di 1 Album: {(check_albums_per_id > 1).sum()}\")\n",
    "\n",
    "print(\"\\n--- Esempio di 10 righe pulite: ---\")\n",
    "print(df[['correct_album', 'id_album', 'id_album_final']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "444161c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['album'] = df['correct_album']\n",
    "df.drop(columns=['album_name', 'album_norm', 'album_name_norm', 'correct_album'], inplace=True)\n",
    "df['id_album'] = df['id_album_final']\n",
    "df.drop(columns=['id_album_final'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "0256faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11166 entries, TR934808 to TR552777\n",
      "Data columns (total 53 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   id_artist             11166 non-null  object        \n",
      " 1   name_artist           11166 non-null  object        \n",
      " 2   title                 11166 non-null  string        \n",
      " 3   featured_artists      11166 non-null  object        \n",
      " 4   language              11036 non-null  object        \n",
      " 5   album                 11161 non-null  object        \n",
      " 6   stats_pageviews       4642 non-null   float64       \n",
      " 7   swear_IT              11039 non-null  float64       \n",
      " 8   swear_EN              11039 non-null  float64       \n",
      " 9   swear_IT_words        11166 non-null  object        \n",
      " 10  swear_EN_words        11039 non-null  object        \n",
      " 11  year                  10728 non-null  float64       \n",
      " 12  month                 9969 non-null   float64       \n",
      " 13  day                   9843 non-null   float64       \n",
      " 14  n_sentences           10963 non-null  float64       \n",
      " 15  n_tokens              10963 non-null  float64       \n",
      " 16  tokens_per_sent       10963 non-null  float64       \n",
      " 17  char_per_tok          11090 non-null  float64       \n",
      " 18  lexical_density       11090 non-null  float64       \n",
      " 19  avg_token_per_clause  10963 non-null  float64       \n",
      " 20  bpm                   11102 non-null  float64       \n",
      " 21  centroid              11102 non-null  float64       \n",
      " 22  rolloff               11102 non-null  float64       \n",
      " 23  flux                  11102 non-null  float64       \n",
      " 24  rms                   11102 non-null  float64       \n",
      " 25  zcr                   11102 non-null  float64       \n",
      " 26  flatness              11102 non-null  float64       \n",
      " 27  spectral_complexity   11102 non-null  float64       \n",
      " 28  pitch                 11102 non-null  float64       \n",
      " 29  loudness              11102 non-null  float64       \n",
      " 30  album_release_date    10827 non-null  datetime64[ns]\n",
      " 31  album_type            11088 non-null  category      \n",
      " 32  disc_number           11088 non-null  Int64         \n",
      " 33  track_number          11088 non-null  Int64         \n",
      " 34  duration_ms           11088 non-null  float64       \n",
      " 35  explicit              11039 non-null  object        \n",
      " 36  popularity            11137 non-null  float64       \n",
      " 37  album_image           11088 non-null  string        \n",
      " 38  id_album              11161 non-null  object        \n",
      " 39  lyrics                11036 non-null  string        \n",
      " 40  modified_popularity   11166 non-null  bool          \n",
      " 41  gender                11166 non-null  category      \n",
      " 42  birth_date            8588 non-null   datetime64[ns]\n",
      " 43  birth_place           8588 non-null   category      \n",
      " 44  nationality           8557 non-null   category      \n",
      " 45  description           10028 non-null  string        \n",
      " 46  active_start          6565 non-null   datetime64[ns]\n",
      " 47  province              8467 non-null   category      \n",
      " 48  region                8024 non-null   category      \n",
      " 49  country               8467 non-null   category      \n",
      " 50  latitude              8588 non-null   float64       \n",
      " 51  longitude             8588 non-null   float64       \n",
      " 52  swear IT words        0 non-null      object        \n",
      "dtypes: Int64(2), bool(1), category(7), datetime64[ns](3), float64(26), object(10), string(4)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf2848",
   "metadata": {},
   "source": [
    "## Stats page views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d9fbf",
   "metadata": {},
   "source": [
    "As considered in data understanding phase, almost 60% of records is missing (Nan) so we decided to drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "3eef90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['stats_pageviews'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2706b",
   "metadata": {},
   "source": [
    "## Year, Month, Day and Album Release Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd2e79",
   "metadata": {},
   "source": [
    "there are multiple nan occurrences in month and day column so we decided to set such records at 01 to create a proper date based on the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "638b9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
    "df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
    "\n",
    "date_components = {\n",
    "    'year': df['year'],  \n",
    "    'month': df['month'].fillna(1),  \n",
    "    'day': df['day'].fillna(1)        \n",
    "}\n",
    "\n",
    "df['date'] = pd.to_datetime(date_components, \n",
    "                                    errors='coerce') \n",
    "df.drop(columns=['year', 'month', 'day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "4283c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_release=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "1f923754",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione= (df_release['date'] > pd.Timestamp.now()) | (df_release['date'].isna()) | (df_release['date']<df_release['active_start'])\n",
    "df_release.loc[condizione, 'date'] = df_release.loc[condizione, 'album_release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "17621d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione= (df_release['album_release_date'] > pd.Timestamp.now()) | (df_release['album_release_date'].isna()) | (df_release['album_release_date']<df_release['active_start'])\n",
    "df_release.loc[condizione, 'album_release_date'] = df_release.loc[condizione, 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94ec15",
   "metadata": {},
   "source": [
    "After cleaning and filtering the dataset, the columns of album_release_date and date are redundant and both provide the same information on when did the track released.\n",
    "\n",
    "We decided to use both column to correct the missing and non valid data and selected the best mode of the tracks in the same album (not the tracks with album_type=single) between the date mode and album_release_date mode.\n",
    "\n",
    "Then we create the column release_date that has the same data for all the tracks in the same album (selected with the previous control) and for singles we decided to use the column date because of more accuracy in the \"mode test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b453a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolo della moda migliore per ciascun album...\n",
      "\n",
      "--- Conteggio finale delle fonti scelte ---\n",
      "best_mode_source\n",
      "date                  1353\n",
      "album_release_date     528\n",
      "none                     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fatto! Colonne 'correct_release_date' e 'best_mode_source' aggiunte.\n",
      "\n",
      "--- Esempio di 10 righe casuali ---\n",
      "                           album       date album_release_date  \\\n",
      "8259           escape from heart 2010-10-10         2017-08-02   \n",
      "9486           fruit joint gusto 2018-05-11         2019-01-18   \n",
      "5938         effetto notte lalba 2023-11-24         2023-11-24   \n",
      "3556               chicopisco ep 1999-01-01         1999-01-01   \n",
      "3319   qualcosa cambiera mixtape 2006-01-01         2006-06-06   \n",
      "6269        sulla riva del fiume 2025-02-01         2025-02-27   \n",
      "10210            sinatra mixtape 2013-01-24         2024-11-15   \n",
      "1776                     bengala 2003-01-01         2016-10-14   \n",
      "103                luga pandemic 2020-03-15         2023-01-01   \n",
      "7846               verano zombie 2007-03-09         2007-01-01   \n",
      "\n",
      "      correct_release_date  \n",
      "8259            2010-10-10  \n",
      "9486            2019-01-18  \n",
      "5938            2023-05-19  \n",
      "3556            1999-01-01  \n",
      "3319            2007-02-18  \n",
      "6269            2025-02-13  \n",
      "10210           2013-03-12  \n",
      "1776            2006-08-09  \n",
      "103             2023-01-01  \n",
      "7846            2007-01-01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65069/87836761.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_album_info = df_release.groupby(group_keys).apply(get_best_mode_info)\n"
     ]
    }
   ],
   "source": [
    "group_keys = ['album'] \n",
    "def get_best_mode_info(group):\n",
    "    \"\"\"\n",
    "    Calcola la moda e la frequenza per 'date' e 'album_release_date'\n",
    "    e restituisce SIA LA FONTE ('date'/'album_release_date') \n",
    "    SIA IL VALORE (la data).\n",
    "    \"\"\"\n",
    "    # Calcola mode e frequenze per 'date'\n",
    "    date_counts = group['date'].value_counts()\n",
    "    date_mode_freq = date_counts.iloc[0] if not date_counts.empty else 0\n",
    "    date_mode_value = date_counts.index[0] if not date_counts.empty else pd.NaT\n",
    "\n",
    "    # Calcola mode e frequenze per 'album_release_date'\n",
    "    release_counts = group['album_release_date'].value_counts()\n",
    "    release_mode_freq = release_counts.iloc[0] if not release_counts.empty else 0\n",
    "    release_mode_value = release_counts.index[0] if not release_counts.empty else pd.NaT\n",
    "\n",
    "    # Confronta le frequenze e definisci fonte e valore\n",
    "    if date_mode_freq > release_mode_freq:\n",
    "        source = 'date'\n",
    "        value = date_mode_value\n",
    "    elif release_mode_freq > date_mode_freq:\n",
    "        source = 'album_release_date'\n",
    "        value = release_mode_value\n",
    "    elif date_mode_freq == 0: # Nessun dato valido\n",
    "        source = 'none'\n",
    "        value = pd.NaT\n",
    "    else: \n",
    "        # Pareggio (date_mode_freq == release_mode_freq > 0)\n",
    "        source = 'date' # Scegliamo 'date' come preferenza\n",
    "        value = date_mode_value\n",
    "    \n",
    "    # Restituisci una Serie con entrambe le info\n",
    "    return pd.Series({\n",
    "        'best_mode_source': source, \n",
    "        'correct_release_date': value\n",
    "    })\n",
    "\n",
    "# 4. Calcola le info migliori per ogni gruppo (album)\n",
    "print(\"Calcolo della moda migliore per ciascun album...\")\n",
    "# best_album_info ora sar√† un DataFrame con colonne 'best_mode_source' e 'correct_release_date'\n",
    "best_album_info = df_release.groupby(group_keys).apply(get_best_mode_info)\n",
    "\n",
    "print(\"\\n--- Conteggio finale delle fonti scelte ---\")\n",
    "final_counts = best_album_info['best_mode_source'].value_counts()\n",
    "print(final_counts)\n",
    "\n",
    "# Unisci (merge) questo DataFrame al DataFrame originale\n",
    "# Pandas unir√† 'best_mode_source' e 'correct_release_date'\n",
    "df_release = df_release.merge(best_album_info, on=group_keys, how='left')\n",
    "\n",
    "print(\"\\nFatto! Colonne 'correct_release_date' e 'best_mode_source' aggiunte.\")\n",
    "\n",
    "# Controlla il risultato (mostrando tutte le colonne rilevanti)\n",
    "print(\"\\n--- Esempio di 10 righe casuali ---\")\n",
    "print(df_release.sample(n=10)[['album', 'date', 'album_release_date', 'correct_release_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "0e89a474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      album       date album_release_date correct_release_date\n",
      "5284              una seria 2013-03-12         2013-03-12           2013-03-12\n",
      "56                      bv3 2020-06-10         2020-10-02           2020-10-02\n",
      "3638  alla fine della notte 2007-06-01         2007-06-01           2007-06-01\n",
      "8787              bipopular 2018-01-19         2022-05-27           2018-04-27\n",
      "594             entertainer 2018-06-08         2018-05-25           2018-05-25\n",
      "7683           la bellavita 2025-03-28         2025-03-28           2025-03-28\n",
      "8267               mm vol 4 2021-11-12         2021-11-12           2021-11-12\n",
      "9744           mr antipatia 2005-01-01         2023-07-24           2005-01-01\n",
      "6151     jax friends deluxe 2015-10-23         2015-12-04           2016-05-20\n",
      "827              fastlife 4 1947-04-09         2021-04-08           2021-04-08\n"
     ]
    }
   ],
   "source": [
    "print(df_release.sample(n=10)[['album', 'date', 'album_release_date', 'correct_release_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "7becc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione = (df_release['album_type'] == 'single')\n",
    "df_release.loc[condizione, 'correct_release_date'] = df_release.loc[condizione, 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "79b95959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame 'df' cleaned!\n",
      "         id_artist  name_artist              title  \\\n",
      "5286   ART40229749       baby k         Certe cose   \n",
      "7858   ART07127070  noyz narcos            Real TV   \n",
      "1615   ART66932389       piotta        Antipopstar   \n",
      "4449   ART83125571        ghali              Chill   \n",
      "2541   ART57730937        inoki  Vecchio Quartiere   \n",
      "6008   ART95365016     bushwaka  Di Tutti I Colori   \n",
      "5605   ART87162895      geolier         NUN SE VER   \n",
      "11155  ART02733420    marracash    Album Trailer 3   \n",
      "631    ART62385172       nerone     Il Cantastorie   \n",
      "7308   ART85046033     gemitaiz   2013 (Accendila)   \n",
      "\n",
      "                     featured_artists language  \\\n",
      "5286                           [J-Ax]     __it   \n",
      "7858   [Gu√®, Vincenzo da Via Anfossi]     __it   \n",
      "1615                         [Afu-Ra]     __it   \n",
      "4449                               []     __it   \n",
      "2541                               []     __it   \n",
      "6008                               []     __it   \n",
      "5605                            [Gu√®]     __it   \n",
      "11155                              []     __it   \n",
      "631                     [Biggie Paul]     __it   \n",
      "7308                               []     __it   \n",
      "\n",
      "                                 album  swear_IT  swear_EN  \\\n",
      "5286                             icona       0.0       2.0   \n",
      "7858                     verano zombie       3.0       0.0   \n",
      "1615                           tommaso       1.0       0.0   \n",
      "4449                             chill       0.0       2.0   \n",
      "2541                             5 dan       2.0       1.0   \n",
      "6008                       pandamonium       0.0       0.0   \n",
      "5605   il coraggio dei bambini atto ii       1.0       0.0   \n",
      "11155           achille idol immortale       0.0       0.0   \n",
      "631                     numero zero ep       1.0       0.0   \n",
      "7308                lunico compromesso       2.0       1.0   \n",
      "\n",
      "             swear_IT_words  swear_EN_words  n_sentences  n_tokens  \\\n",
      "5286                     []  [pussy, vulva]         87.0     503.0   \n",
      "7858       [fottuto, merda]              []         55.0     447.0   \n",
      "1615                [cesso]              []         68.0     498.0   \n",
      "4449                     []          [sexy]         51.0     421.0   \n",
      "2541   [cazzeggiare, cazzo]          [rape]         92.0    1020.0   \n",
      "6008                     []              []         59.0     396.0   \n",
      "5605                [palle]              []         52.0     533.0   \n",
      "11155                    []              []          2.0      21.0   \n",
      "631               [stronzo]              []         58.0     525.0   \n",
      "7308       [fottuto, merda]         [negro]         40.0     360.0   \n",
      "\n",
      "       tokens_per_sent  char_per_tok  lexical_density  avg_token_per_clause  \\\n",
      "5286          5.781609      4.198770         0.549180              4.657407   \n",
      "7858          8.127273      4.402985         0.572139              7.842105   \n",
      "1615          7.323529      4.434389         0.538462             10.595745   \n",
      "4449          8.254902      3.816129         0.496774              9.355556   \n",
      "2541         11.086957      4.205707         0.518430             10.967742   \n",
      "6008          6.711864      4.117048         0.597964              9.209302   \n",
      "5605         10.250000      3.814727         0.567696              7.202703   \n",
      "11155        10.500000      3.857143         0.476190              5.250000   \n",
      "631           9.051724      4.021526         0.477495              7.094595   \n",
      "7308          9.000000      4.230769         0.501672              7.659574   \n",
      "\n",
      "          bpm  centroid    rolloff    flux     rms     zcr  flatness  \\\n",
      "5286   123.47    0.1675  2383.5206  1.3834  0.2565  0.0847    0.7910   \n",
      "7858    97.46    0.1535  1047.5824  1.3111  0.2346  0.0555    0.9561   \n",
      "1615    86.57    0.1545  3082.3014  1.3371  0.1513  0.1017    0.7949   \n",
      "4449   129.49    0.1288  1424.5692  1.2726  0.2726  0.0593    0.8644   \n",
      "2541    97.21    0.0860  1145.9875  1.2727  0.3216  0.0410    0.9412   \n",
      "6008   108.05    0.1465  1901.4347  1.3007  0.2809  0.0631    0.8137   \n",
      "5605   125.99    0.1329  1268.5702  1.3659  0.2120  0.0508    0.8625   \n",
      "11155  110.15    0.0515   588.6836  0.9108  0.0408  0.0245    0.8104   \n",
      "631    172.27    0.2113  3055.9194  1.1897  0.2120  0.1100    0.8302   \n",
      "7308    80.03    0.1674  1933.9949  1.2690  0.2550  0.0790    0.8983   \n",
      "\n",
      "       spectral_complexity      pitch  loudness album_release_date album_type  \\\n",
      "5286               34.3438  2439.7871   28.7863         2018-11-16      album   \n",
      "7858               32.4225  2515.6049   24.3184         2007-01-01      album   \n",
      "1615               29.4201  2102.4015   14.0728                NaT      album   \n",
      "4449               31.8220  2266.5329   30.7459         2025-05-16     single   \n",
      "2541               34.9703  2374.6176   37.9401         2025-05-16      album   \n",
      "6008               41.6500  2165.3677   31.3734         2025-05-23     single   \n",
      "5605               20.2055  2525.4178   22.9568         2023-01-06      album   \n",
      "11155               4.1677  1949.7866    2.7723         2014-12-17      album   \n",
      "631                29.1662  1814.7345   22.6812         2020-11-13      album   \n",
      "7308               41.1844  2237.6413   27.7973         2013-05-28      album   \n",
      "\n",
      "       disc_number  track_number  duration_ms explicit  popularity  \\\n",
      "5286             1             4     216773.0    False        27.0   \n",
      "7858             1            12     155373.0    False        30.0   \n",
      "1615             1             8     269306.0    False         1.0   \n",
      "4449             1             1     135692.0    False        69.0   \n",
      "2541             1             2     246000.0     True        31.0   \n",
      "6008             1             1     212148.0    False        72.0   \n",
      "5605             1             6     158666.0     True        47.0   \n",
      "11155            1             5     230365.0     True        34.0   \n",
      "631              2             4     163073.0    False        63.0   \n",
      "7308             1             1     134040.0     True        27.0   \n",
      "\n",
      "                                             album_image   id_album  \\\n",
      "5286   https://i.scdn.co/image/ab67616d0000b2733c71f8...  ALB673259   \n",
      "7858   https://i.scdn.co/image/ab67616d0000b273bfc8c7...  ALB233745   \n",
      "1615   https://i.scdn.co/image/ab67616d0000b273db5ff5...  ALB681595   \n",
      "4449   https://i.scdn.co/image/ab67616d0000b2732ad04f...  ALB890062   \n",
      "2541   https://i.scdn.co/image/ab67616d0000b2738cc02a...  ALB230346   \n",
      "6008   https://i.scdn.co/image/ab67616d0000b2739c7b6f...  ALB186404   \n",
      "5605   https://i.scdn.co/image/ab67616d0000b273a43bc8...  ALB108052   \n",
      "11155  https://i.scdn.co/image/ab67616d0000b2730bb01d...  ALB759683   \n",
      "631    https://i.scdn.co/image/ab67616d0000b27385ffac...  ALB670161   \n",
      "7308   https://i.scdn.co/image/ab67616d0000b273c83e8c...  ALB725158   \n",
      "\n",
      "                                                  lyrics  modified_popularity  \\\n",
      "5286   Baby K uh\\nJ-Ax\\n\\nIo ieri sera stavo fuori co...                False   \n",
      "7858   Eoh, Narcos Noyz boss e Anfossi boys\\nDogo mol...                False   \n",
      "1615   Niente superstar, ma stelle del quartiere\\nEd ...                False   \n",
      "4449   Se penso alla mia vita, Jurassic\\nCose che non...                False   \n",
      "2541   Mi ritrovo per le strade del mio vecchio quart...                False   \n",
      "6008   Rimbalzo nel locale come una pallina\\nA casa n...                False   \n",
      "5605   Ah-ah\\nLa fama mixata all'arroganza maneggiala...                False   \n",
      "11155  Ho sempre giocato contro me stesso\\nOra √® arri...                False   \n",
      "631    Take me in your arms like you used to do\\nMake...                False   \n",
      "7308   2013, finalmente ho fatto un disco (Vai)\\nAdes...                False   \n",
      "\n",
      "      gender birth_date birth_place nationality  \\\n",
      "5286       F 1983-02-05   Singapore      Italia   \n",
      "7858       M 1979-12-15        Roma      Italia   \n",
      "1615       M 1973-04-26        Roma      Italia   \n",
      "4449       M 1993-05-21      Milano      Italia   \n",
      "2541       M 1979-10-02        Roma      Italia   \n",
      "6008       M        NaT         NaN         NaN   \n",
      "5605       M 2000-03-23      Napoli      Italia   \n",
      "11155      M 1979-05-22     Nicosia      Italia   \n",
      "631        M        NaT         NaN         NaN   \n",
      "7308       M 1988-11-04        Roma      Italia   \n",
      "\n",
      "                                             description active_start  \\\n",
      "5286               cantautrice e rapper italiana (1983-)   2007-01-01   \n",
      "7858   rapper e produttore discografico italiano (1979-)   1996-01-01   \n",
      "1615   rapper e produttore discografico italiano (1973-)   1994-01-01   \n",
      "4449          rapper e cantautore italo-tunisino (1993-)   2011-01-01   \n",
      "2541    rapper e produttore discografico italiano (1979)   1996-01-01   \n",
      "6008                                                <NA>          NaT   \n",
      "5605                             rapper italiano (2000-)          NaT   \n",
      "11155  rapper e produttore discografico italiano (1979-)   1999-01-01   \n",
      "631                      opera lirica di Pietro Mascagni          NaT   \n",
      "7308    rapper e produttore discografico italiano (1988)   2003-01-01   \n",
      "\n",
      "      province     region country   latitude  longitude swear IT words  \\\n",
      "5286       NaN        NaN     NaN  45.080627   7.670717            NaN   \n",
      "7858      Roma      Lazio  Italia  41.893320  12.482932            NaN   \n",
      "1615      Roma      Lazio  Italia  41.893320  12.482932            NaN   \n",
      "4449    Milano  Lombardia  Italia  45.464194   9.189635            NaN   \n",
      "2541      Roma      Lazio  Italia  41.893320  12.482932            NaN   \n",
      "6008       NaN        NaN     NaN        NaN        NaN            NaN   \n",
      "5605    Napoli   Campania  Italia  40.835885  14.248768            NaN   \n",
      "11155     Enna    Sicilia  Italia  37.747452  14.397271            NaN   \n",
      "631        NaN        NaN     NaN        NaN        NaN            NaN   \n",
      "7308      Roma      Lazio  Italia  41.893320  12.482932            NaN   \n",
      "\n",
      "            date    best_mode_source release_date  \n",
      "5286  2018-11-16  album_release_date   2018-11-16  \n",
      "7858  2007-03-09  album_release_date   2007-01-01  \n",
      "1615         NaT                date   2004-01-01  \n",
      "4449  2025-05-16                date   2025-05-16  \n",
      "2541  2001-01-01                date   2001-01-01  \n",
      "6008  2015-03-23                date   2015-03-23  \n",
      "5605  2023-01-06  album_release_date   2023-01-06  \n",
      "11155 2019-10-29  album_release_date   2014-12-17  \n",
      "631   2013-09-21  album_release_date   2014-11-28  \n",
      "7308  2013-05-28  album_release_date   2013-05-28  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65069/1771844910.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_album_info_df = df.groupby(group_keys).apply(get_best_mode_info)\n"
     ]
    }
   ],
   "source": [
    "group_keys = ['album'] \n",
    "\n",
    "best_album_info_df = df.groupby(group_keys).apply(get_best_mode_info)\n",
    "\n",
    "df = df.merge(best_album_info_df, on=group_keys, how='left')\n",
    "df.rename(columns={'correct_release_date': 'release_date'}, inplace=True)\n",
    "\n",
    "\n",
    "print(\"\\nDataFrame 'df' cleaned!\")\n",
    "print(df.sample(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f988167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>album</th>\n",
       "      <th>active_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2010-08-23</td>\n",
       "      <td>the interview</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1975-09-12</td>\n",
       "      <td>wish you were here</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>erbavoglio</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>dinamite</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1991-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>NaT</td>\n",
       "      <td>zora la vampira</td>\n",
       "      <td>1991-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1991-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1991-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>1933-12-21</td>\n",
       "      <td>balances options</td>\n",
       "      <td>2002-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>classe 73</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>2000-11-17</td>\n",
       "      <td>greatest hits</td>\n",
       "      <td>2007-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>NaT</td>\n",
       "      <td>mindstate</td>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785</th>\n",
       "      <td>NaT</td>\n",
       "      <td>neslibook capitolo 1</td>\n",
       "      <td>1990-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>2009-07-01</td>\n",
       "      <td>songs the beatles wrote</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>2001-03-06</td>\n",
       "      <td>one take fm free mic season 4</td>\n",
       "      <td>2007-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     release_date                          album active_start\n",
       "289    2010-08-23                  the interview   2015-01-01\n",
       "436    1975-09-12             wish you were here   2012-01-01\n",
       "1142   2012-01-01                     erbavoglio   2013-01-01\n",
       "1162   2008-04-15                       dinamite   2013-01-01\n",
       "2304          NaT                           <NA>   2009-01-01\n",
       "3680          NaT                           <NA>   1991-01-01\n",
       "3711          NaT                zora la vampira   1991-01-01\n",
       "3734          NaT                           <NA>   1991-01-01\n",
       "3738          NaT                           <NA>   1991-01-01\n",
       "4601   1933-12-21               balances options   2002-01-01\n",
       "4972   2003-01-01                      classe 73   2015-01-01\n",
       "5290   2000-11-17                  greatest hits   2007-01-01\n",
       "5741          NaT                      mindstate   2005-01-01\n",
       "6785          NaT           neslibook capitolo 1   1990-01-01\n",
       "7001   2009-07-01        songs the beatles wrote   2011-01-01\n",
       "9261          NaT                           <NA>          NaT\n",
       "9987   2001-03-06  one take fm free mic season 4   2007-01-01"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condizione= (df['release_date'] > pd.Timestamp.now()) | (df['release_date'].isna()) | (df['release_date']<df['active_start'])\n",
    "dati_filtrati = df.loc[condizione, ['release_date', 'album','active_start']]\n",
    "dati_filtrati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "2f597658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_artist</th>\n",
       "      <th>name_artist</th>\n",
       "      <th>title</th>\n",
       "      <th>featured_artists</th>\n",
       "      <th>language</th>\n",
       "      <th>album</th>\n",
       "      <th>swear_IT</th>\n",
       "      <th>swear_EN</th>\n",
       "      <th>swear_IT_words</th>\n",
       "      <th>swear_EN_words</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>tokens_per_sent</th>\n",
       "      <th>char_per_tok</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>avg_token_per_clause</th>\n",
       "      <th>bpm</th>\n",
       "      <th>centroid</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>flux</th>\n",
       "      <th>rms</th>\n",
       "      <th>zcr</th>\n",
       "      <th>flatness</th>\n",
       "      <th>spectral_complexity</th>\n",
       "      <th>pitch</th>\n",
       "      <th>loudness</th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>album_type</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>track_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>popularity</th>\n",
       "      <th>album_image</th>\n",
       "      <th>id_album</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>modified_popularity</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>birth_place</th>\n",
       "      <th>nationality</th>\n",
       "      <th>description</th>\n",
       "      <th>active_start</th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>swear IT words</th>\n",
       "      <th>date</th>\n",
       "      <th>best_mode_source</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Il cielo su Roma</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[sega, stupida]</td>\n",
       "      <td>[]</td>\n",
       "      <td>89.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8.146067</td>\n",
       "      <td>3.875362</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>7.107843</td>\n",
       "      <td>95.00</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>1505.1086</td>\n",
       "      <td>1.3623</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.9539</td>\n",
       "      <td>21.8780</td>\n",
       "      <td>2005.7467</td>\n",
       "      <td>9.6318</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>288066.0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Ah, ah, esco di casa e ci sto dentro\\nLa mia c...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9134</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Il tuo diavolo</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[fregare]</td>\n",
       "      <td>[nude]</td>\n",
       "      <td>95.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>8.652632</td>\n",
       "      <td>4.175866</td>\n",
       "      <td>0.450578</td>\n",
       "      <td>5.337662</td>\n",
       "      <td>87.96</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>1190.9466</td>\n",
       "      <td>1.4765</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>19.2274</td>\n",
       "      <td>2558.6629</td>\n",
       "      <td>17.5232</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>295932.0</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Sempre, sempre con me, sempre contro di me\\nIl...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Vita</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[cesso, incazzato, puttana]</td>\n",
       "      <td>[]</td>\n",
       "      <td>116.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>7.698276</td>\n",
       "      <td>3.993910</td>\n",
       "      <td>0.503045</td>\n",
       "      <td>5.993289</td>\n",
       "      <td>96.02</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>1130.9569</td>\n",
       "      <td>1.2475</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.8494</td>\n",
       "      <td>9.2386</td>\n",
       "      <td>2607.0102</td>\n",
       "      <td>3.8135</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>306519.0</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Uh uh\\nChi c'√®? Chi c'√®? S√¨\\nChi c'√®? Chi c'√®-...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Prova microfono</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[cazzo, selvaggio, toro]</td>\n",
       "      <td>[]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>8.710938</td>\n",
       "      <td>4.081192</td>\n",
       "      <td>0.484070</td>\n",
       "      <td>6.798780</td>\n",
       "      <td>90.11</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1797.8709</td>\n",
       "      <td>1.3868</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>28.8479</td>\n",
       "      <td>2578.8910</td>\n",
       "      <td>24.0631</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>331586.0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Uno, due, uno, provo i microfoni\\nQuesto √® il ...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Toro scatenato</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[cazzo, toro]</td>\n",
       "      <td>[hardcore]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>8.620000</td>\n",
       "      <td>3.887728</td>\n",
       "      <td>0.479112</td>\n",
       "      <td>6.338235</td>\n",
       "      <td>91.82</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>1136.0479</td>\n",
       "      <td>1.1172</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>23.4387</td>\n",
       "      <td>1833.1263</td>\n",
       "      <td>13.4173</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>267932.0</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>S√¨, s√¨, nun se ferma mai\\nS√¨, s√¨, non lo fermi...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>King Kong vs. Godzilla</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[cazzo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>87.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>8.080460</td>\n",
       "      <td>4.345291</td>\n",
       "      <td>0.517190</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>172.27</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>918.0454</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.9297</td>\n",
       "      <td>17.7669</td>\n",
       "      <td>2558.4015</td>\n",
       "      <td>14.0608</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>303346.0</td>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Mi arrampico come King Kong su un palazzo\\nSe ...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9166</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Spinto da una sensazione</td>\n",
       "      <td>[Esa]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>79.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>8.974684</td>\n",
       "      <td>4.161339</td>\n",
       "      <td>0.484018</td>\n",
       "      <td>7.463158</td>\n",
       "      <td>85.17</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>1782.5932</td>\n",
       "      <td>1.5195</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.8078</td>\n",
       "      <td>14.6565</td>\n",
       "      <td>2713.2143</td>\n",
       "      <td>9.8978</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>349052.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Uh, uh\\nEh s√¨ eh, eh s√¨ eh\\nCheck uno-due com'...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Scienza doppia H</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>104.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>9.201923</td>\n",
       "      <td>4.143017</td>\n",
       "      <td>0.501676</td>\n",
       "      <td>6.787234</td>\n",
       "      <td>172.27</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>1611.4928</td>\n",
       "      <td>1.3787</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>32.0804</td>\n",
       "      <td>2536.2920</td>\n",
       "      <td>25.2407</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>288066.0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>MC per MC il meglio sta qui\\nE se non sono il ...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Preparati</td>\n",
       "      <td>[2 Buoni Motivi]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>101.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>8.445545</td>\n",
       "      <td>4.354712</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>5.965035</td>\n",
       "      <td>172.26</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>1615.2015</td>\n",
       "      <td>1.3707</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>23.4967</td>\n",
       "      <td>2404.2242</td>\n",
       "      <td>15.9587</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>302959.0</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>\"S√¨, s√¨, s√¨, s√¨ per tutti i massicci all'ascol...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Sul tempo</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>103.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>8.456311</td>\n",
       "      <td>4.136250</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>6.751938</td>\n",
       "      <td>108.86</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>2398.4141</td>\n",
       "      <td>1.2751</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>29.5651</td>\n",
       "      <td>2013.3644</td>\n",
       "      <td>12.8951</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>326586.0</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Seh, seh, seh, seh, seh\\n\\nSul tempo adesso no...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9177</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Dissetante + Potente (Tamarindo‚Äôs Flavour)</td>\n",
       "      <td>[]</td>\n",
       "      <td>__it</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>101.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>7.465347</td>\n",
       "      <td>3.920301</td>\n",
       "      <td>0.499248</td>\n",
       "      <td>6.130081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>235386.0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>Dimmi Masito che c'√®? C'√® che sono qui\\nDammi ...</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Rest in Party</td>\n",
       "      <td>[Ice One]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.97</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>1396.9510</td>\n",
       "      <td>1.2651</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>35.3114</td>\n",
       "      <td>2671.2660</td>\n",
       "      <td>21.8177</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>176519.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Intro</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.22</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>988.4781</td>\n",
       "      <td>1.0846</td>\n",
       "      <td>0.2466</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>33.7391</td>\n",
       "      <td>1801.2735</td>\n",
       "      <td>27.1311</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62079.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9184</th>\n",
       "      <td>ART85821920</td>\n",
       "      <td>colle der fomento</td>\n",
       "      <td>Outro (Scienza doppia H)</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>scienza doppia h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.55</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>2613.4504</td>\n",
       "      <td>1.2641</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>9.8277</td>\n",
       "      <td>2639.9455</td>\n",
       "      <td>5.9215</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>album</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>55279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273dd31ad...</td>\n",
       "      <td>ALB384607</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gruppo musicale italiano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_artist        name_artist  \\\n",
       "9120  ART85821920  colle der fomento   \n",
       "9134  ART85821920  colle der fomento   \n",
       "9136  ART85821920  colle der fomento   \n",
       "9151  ART85821920  colle der fomento   \n",
       "9160  ART85821920  colle der fomento   \n",
       "9164  ART85821920  colle der fomento   \n",
       "9166  ART85821920  colle der fomento   \n",
       "9169  ART85821920  colle der fomento   \n",
       "9171  ART85821920  colle der fomento   \n",
       "9175  ART85821920  colle der fomento   \n",
       "9177  ART85821920  colle der fomento   \n",
       "9180  ART85821920  colle der fomento   \n",
       "9181  ART85821920  colle der fomento   \n",
       "9184  ART85821920  colle der fomento   \n",
       "\n",
       "                                           title  featured_artists language  \\\n",
       "9120                            Il cielo su Roma                []     __it   \n",
       "9134                              Il tuo diavolo                []     __it   \n",
       "9136                                        Vita                []     __it   \n",
       "9151                             Prova microfono                []     __it   \n",
       "9160                              Toro scatenato                []     __it   \n",
       "9164                      King Kong vs. Godzilla                []     __it   \n",
       "9166                    Spinto da una sensazione             [Esa]     __it   \n",
       "9169                            Scienza doppia H                []     __it   \n",
       "9171                                   Preparati  [2 Buoni Motivi]     __it   \n",
       "9175                                   Sul tempo                []     __it   \n",
       "9177  Dissetante + Potente (Tamarindo‚Äôs Flavour)                []     __it   \n",
       "9180                               Rest in Party         [Ice One]     <NA>   \n",
       "9181                                       Intro                []     <NA>   \n",
       "9184                    Outro (Scienza doppia H)                []     <NA>   \n",
       "\n",
       "                 album  swear_IT  swear_EN               swear_IT_words  \\\n",
       "9120  scienza doppia h       2.0       0.0              [sega, stupida]   \n",
       "9134  scienza doppia h       1.0       1.0                    [fregare]   \n",
       "9136  scienza doppia h       3.0       0.0  [cesso, incazzato, puttana]   \n",
       "9151  scienza doppia h       3.0       0.0     [cazzo, selvaggio, toro]   \n",
       "9160  scienza doppia h       7.0       1.0                [cazzo, toro]   \n",
       "9164  scienza doppia h       1.0       0.0                      [cazzo]   \n",
       "9166  scienza doppia h       0.0       0.0                           []   \n",
       "9169  scienza doppia h       0.0       0.0                           []   \n",
       "9171  scienza doppia h       0.0       0.0                           []   \n",
       "9175  scienza doppia h       0.0       0.0                           []   \n",
       "9177  scienza doppia h       0.0       0.0                           []   \n",
       "9180  scienza doppia h       NaN       NaN                           []   \n",
       "9181  scienza doppia h       NaN       NaN                           []   \n",
       "9184  scienza doppia h       NaN       NaN                           []   \n",
       "\n",
       "     swear_EN_words  n_sentences  n_tokens  tokens_per_sent  char_per_tok  \\\n",
       "9120             []         89.0     725.0         8.146067      3.875362   \n",
       "9134         [nude]         95.0     822.0         8.652632      4.175866   \n",
       "9136             []        116.0     893.0         7.698276      3.993910   \n",
       "9151             []        128.0    1115.0         8.710938      4.081192   \n",
       "9160     [hardcore]        100.0     862.0         8.620000      3.887728   \n",
       "9164             []         87.0     703.0         8.080460      4.345291   \n",
       "9166             []         79.0     709.0         8.974684      4.161339   \n",
       "9169             []        104.0     957.0         9.201923      4.143017   \n",
       "9171             []        101.0     853.0         8.445545      4.354712   \n",
       "9175             []        103.0     871.0         8.456311      4.136250   \n",
       "9177             []        101.0     754.0         7.465347      3.920301   \n",
       "9180           <NA>          NaN       NaN              NaN      6.000000   \n",
       "9181           <NA>          NaN       NaN              NaN      4.500000   \n",
       "9184           <NA>          NaN       NaN              NaN      6.333333   \n",
       "\n",
       "      lexical_density  avg_token_per_clause     bpm  centroid    rolloff  \\\n",
       "9120         0.463768              7.107843   95.00    0.1350  1505.1086   \n",
       "9134         0.450578              5.337662   87.96    0.1125  1190.9466   \n",
       "9136         0.503045              5.993289   96.02    0.0847  1130.9569   \n",
       "9151         0.484070              6.798780   90.11    0.0999  1797.8709   \n",
       "9160         0.479112              6.338235   91.82    0.0902  1136.0479   \n",
       "9164         0.517190              6.333333  172.27    0.0850   918.0454   \n",
       "9166         0.484018              7.463158   85.17    0.1204  1782.5932   \n",
       "9169         0.501676              6.787234  172.27    0.1127  1611.4928   \n",
       "9171         0.557592              5.965035  172.26    0.1279  1615.2015   \n",
       "9175         0.493750              6.751938  108.86    0.1432  2398.4141   \n",
       "9177         0.499248              6.130081     NaN       NaN        NaN   \n",
       "9180         0.600000                   NaN  127.97    0.1132  1396.9510   \n",
       "9181         0.500000                   NaN  162.22    0.1078   988.4781   \n",
       "9184         0.833333                   NaN  161.55    0.1234  2613.4504   \n",
       "\n",
       "        flux     rms     zcr  flatness  spectral_complexity      pitch  \\\n",
       "9120  1.3623  0.1172  0.0613    0.9539              21.8780  2005.7467   \n",
       "9134  1.4765  0.1761  0.0468    0.9290              19.2274  2558.6629   \n",
       "9136  1.2475  0.0568  0.0419    0.8494               9.2386  2607.0102   \n",
       "9151  1.3868  0.2196  0.0625    0.3275              28.8479  2578.8910   \n",
       "9160  1.1172  0.1409  0.0445    0.9489              23.4387  1833.1263   \n",
       "9164  1.0980  0.1443  0.0356    0.9297              17.7669  2558.4015   \n",
       "9166  1.5195  0.1102  0.0635    0.8078              14.6565  2713.2143   \n",
       "9169  1.3787  0.2355  0.0593    0.9097              32.0804  2536.2920   \n",
       "9171  1.3707  0.1664  0.0593    0.9137              23.4967  2404.2242   \n",
       "9175  1.2751  0.1411  0.0810    0.8343              29.5651  2013.3644   \n",
       "9177     NaN     NaN     NaN       NaN                  NaN        NaN   \n",
       "9180  1.2651  0.2099  0.0558    0.9512              35.3114  2671.2660   \n",
       "9181  1.0846  0.2466  0.0462    0.8829              33.7391  1801.2735   \n",
       "9184  1.2641  0.0707  0.0871    0.7677               9.8277  2639.9455   \n",
       "\n",
       "      loudness album_release_date album_type  disc_number  track_number  \\\n",
       "9120    9.6318         1999-01-01      album            1             9   \n",
       "9134   17.5232         1999-01-01      album            1            13   \n",
       "9136    3.8135         1999-01-01      album            1             3   \n",
       "9151   24.0631         1999-01-01      album            1             2   \n",
       "9160   13.4173         1999-01-01      album            1             8   \n",
       "9164   14.0608         1999-01-01      album            1            12   \n",
       "9166    9.8978         1999-01-01      album            1            10   \n",
       "9169   25.2407         1999-01-01      album            1             9   \n",
       "9171   15.9587         1999-01-01      album            1             6   \n",
       "9175   12.8951         1999-01-01      album            1             4   \n",
       "9177       NaN         1999-01-01      album            1             5   \n",
       "9180   21.8177         1999-01-01      album            1             7   \n",
       "9181   27.1311         1999-01-01      album            1             1   \n",
       "9184    5.9215         1999-01-01      album            1            14   \n",
       "\n",
       "      duration_ms explicit  popularity  \\\n",
       "9120     288066.0    False        42.0   \n",
       "9134     295932.0    False        19.0   \n",
       "9136     306519.0     True        30.0   \n",
       "9151     331586.0    False        24.0   \n",
       "9160     267932.0     True        20.0   \n",
       "9164     303346.0     True        14.0   \n",
       "9166     349052.0    False        12.0   \n",
       "9169     288066.0    False        42.0   \n",
       "9171     302959.0    False        13.0   \n",
       "9175     326586.0    False        13.0   \n",
       "9177     235386.0    False        16.0   \n",
       "9180     176519.0      NaN        11.0   \n",
       "9181      62079.0      NaN        11.0   \n",
       "9184      55279.0      NaN         7.0   \n",
       "\n",
       "                                            album_image   id_album  \\\n",
       "9120  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9134  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9136  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9151  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9160  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9164  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9166  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9169  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9171  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9175  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9177  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9180  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9181  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "9184  https://i.scdn.co/image/ab67616d0000b273dd31ad...  ALB384607   \n",
       "\n",
       "                                                 lyrics  modified_popularity  \\\n",
       "9120  Ah, ah, esco di casa e ci sto dentro\\nLa mia c...                False   \n",
       "9134  Sempre, sempre con me, sempre contro di me\\nIl...                False   \n",
       "9136  Uh uh\\nChi c'√®? Chi c'√®? S√¨\\nChi c'√®? Chi c'√®-...                False   \n",
       "9151  Uno, due, uno, provo i microfoni\\nQuesto √® il ...                False   \n",
       "9160  S√¨, s√¨, nun se ferma mai\\nS√¨, s√¨, non lo fermi...                False   \n",
       "9164  Mi arrampico come King Kong su un palazzo\\nSe ...                False   \n",
       "9166  Uh, uh\\nEh s√¨ eh, eh s√¨ eh\\nCheck uno-due com'...                False   \n",
       "9169  MC per MC il meglio sta qui\\nE se non sono il ...                False   \n",
       "9171  \"S√¨, s√¨, s√¨, s√¨ per tutti i massicci all'ascol...                False   \n",
       "9175  Seh, seh, seh, seh, seh\\n\\nSul tempo adesso no...                False   \n",
       "9177  Dimmi Masito che c'√®? C'√® che sono qui\\nDammi ...                False   \n",
       "9180                                               <NA>                False   \n",
       "9181                                               <NA>                False   \n",
       "9184                                               <NA>                False   \n",
       "\n",
       "     gender birth_date birth_place nationality               description  \\\n",
       "9120      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9134      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9136      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9151      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9160      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9164      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9166      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9169      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9171      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9175      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9177      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9180      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9181      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "9184      M        NaT         NaN         NaN  gruppo musicale italiano   \n",
       "\n",
       "     active_start province region country  latitude  longitude swear IT words  \\\n",
       "9120          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9134          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9136          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9151          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9160          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9164          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9166          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9169          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9171          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9175          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9177          NaT      NaN    NaN     NaN       NaN        NaN            NaN   \n",
       "9180          NaT      NaN    NaN     NaN       NaN        NaN           <NA>   \n",
       "9181          NaT      NaN    NaN     NaN       NaN        NaN           <NA>   \n",
       "9184          NaT      NaN    NaN     NaN       NaN        NaN           <NA>   \n",
       "\n",
       "           date best_mode_source release_date  \n",
       "9120 1999-01-01             date   1999-01-01  \n",
       "9134 1999-01-01             date   1999-01-01  \n",
       "9136 1999-01-01             date   1999-01-01  \n",
       "9151 1999-01-01             date   1999-01-01  \n",
       "9160 1999-01-01             date   1999-01-01  \n",
       "9164 1999-01-01             date   1999-01-01  \n",
       "9166 1999-01-01             date   1999-01-01  \n",
       "9169 1999-01-01             date   1999-01-01  \n",
       "9171 1999-01-01             date   1999-01-01  \n",
       "9175 1999-01-01             date   1999-01-01  \n",
       "9177 1999-01-01             date   1999-01-01  \n",
       "9180 1999-01-01             date   1999-01-01  \n",
       "9181 1999-01-01             date   1999-01-01  \n",
       "9184 1999-01-01             date   1999-01-01  "
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['album']=='scienza doppia h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "e47d0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione= (df['release_date'].isna()) | (df['release_date']<df['active_start'])\n",
    "df.loc[condizione, 'release_date'] = pd.NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e00b3",
   "metadata": {},
   "source": [
    "Active start was remodeled and filled the first date recorded of their tracks/albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "aa8a79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['active_start'] = df['active_start'].fillna(\n",
    "    df.groupby('name_artist')['release_date'].transform('min')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "fa9b6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = ['album_release_date', 'date', 'best_mode_source','new_release']\n",
    "df.drop(columns=col_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "ddaf2c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11166 entries, 0 to 11165\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   id_artist             11166 non-null  object        \n",
      " 1   name_artist           11166 non-null  object        \n",
      " 2   title                 11166 non-null  string        \n",
      " 3   featured_artists      11166 non-null  object        \n",
      " 4   language              11036 non-null  object        \n",
      " 5   album                 11161 non-null  object        \n",
      " 6   swear_IT              11039 non-null  float64       \n",
      " 7   swear_EN              11039 non-null  float64       \n",
      " 8   swear_IT_words        11166 non-null  object        \n",
      " 9   swear_EN_words        11039 non-null  object        \n",
      " 10  n_sentences           10963 non-null  float64       \n",
      " 11  n_tokens              10963 non-null  float64       \n",
      " 12  tokens_per_sent       10963 non-null  float64       \n",
      " 13  char_per_tok          11090 non-null  float64       \n",
      " 14  lexical_density       11090 non-null  float64       \n",
      " 15  avg_token_per_clause  10963 non-null  float64       \n",
      " 16  bpm                   11102 non-null  float64       \n",
      " 17  centroid              11102 non-null  float64       \n",
      " 18  rolloff               11102 non-null  float64       \n",
      " 19  flux                  11102 non-null  float64       \n",
      " 20  rms                   11102 non-null  float64       \n",
      " 21  zcr                   11102 non-null  float64       \n",
      " 22  flatness              11102 non-null  float64       \n",
      " 23  spectral_complexity   11102 non-null  float64       \n",
      " 24  pitch                 11102 non-null  float64       \n",
      " 25  loudness              11102 non-null  float64       \n",
      " 26  album_type            11088 non-null  category      \n",
      " 27  disc_number           11088 non-null  Int64         \n",
      " 28  track_number          11088 non-null  Int64         \n",
      " 29  duration_ms           11088 non-null  float64       \n",
      " 30  explicit              11039 non-null  object        \n",
      " 31  popularity            11137 non-null  float64       \n",
      " 32  album_image           11088 non-null  string        \n",
      " 33  id_album              11161 non-null  object        \n",
      " 34  lyrics                11036 non-null  string        \n",
      " 35  modified_popularity   11166 non-null  bool          \n",
      " 36  gender                11166 non-null  category      \n",
      " 37  birth_date            8588 non-null   datetime64[ns]\n",
      " 38  birth_place           8588 non-null   category      \n",
      " 39  nationality           8557 non-null   category      \n",
      " 40  description           10028 non-null  string        \n",
      " 41  active_start          11166 non-null  datetime64[ns]\n",
      " 42  province              8467 non-null   category      \n",
      " 43  region                8024 non-null   category      \n",
      " 44  country               8467 non-null   category      \n",
      " 45  latitude              8588 non-null   float64       \n",
      " 46  longitude             8588 non-null   float64       \n",
      " 47  swear IT words        0 non-null      object        \n",
      " 48  release_date          11149 non-null  datetime64[ns]\n",
      "dtypes: Int64(2), bool(1), category(7), datetime64[ns](3), float64(22), object(10), string(4)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2f1e4",
   "metadata": {},
   "source": [
    "## Popularity and Modified_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1084a",
   "metadata": {},
   "source": [
    "When modified_popularity is 'true' (78 occurrences) the related popularity occurrence is not in the correct format.\n",
    "We decided to drop the column modified_popularity and set the invalid popularity records to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "a72b80cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "pop=df[df['modified_popularity']==True]\n",
    "print(len(pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "a7633e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>modified_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>-654.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>147413.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>164032.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>884794.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>-119.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>-606.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>-286.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      popularity  modified_popularity\n",
       "1932         NaN                 True\n",
       "2304         NaN                 True\n",
       "3286      -654.0                 True\n",
       "3667    147413.0                 True\n",
       "3668    164032.0                 True\n",
       "...          ...                  ...\n",
       "3737         NaN                 True\n",
       "3738    884794.0                 True\n",
       "3739      -119.0                 True\n",
       "6390      -606.0                 True\n",
       "9261      -286.0                 True\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condizione= (df['popularity']<0) | (df['popularity']>100) | (df['popularity'].isna())\n",
    "dati_filtrati = df.loc[condizione, ['popularity', 'modified_popularity']]\n",
    "dati_filtrati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "622b166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione= (df['popularity']<0) | (df['popularity']>100)\n",
    "df.loc[condizione, 'popularity'] = np.nan\n",
    "df.drop(columns=['modified_popularity'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c6238",
   "metadata": {},
   "source": [
    "## Swear words control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a99c24",
   "metadata": {},
   "source": [
    "We checked if the column Swear_IT and Swear_EN are coherent with the lyrics and their related Swear_IT_words and Swear_EN_words lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "225fd676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3: Riconteggio delle parole nei testi (pu√≤ richiedere tempo)...\n",
      "2/3: Confronto dei conteggi...\n",
      "3/3: Controllo completato.\n",
      "\n",
      "‚úÖ Controllo superato! Tutti i conteggi 'swear_IT' corrispondono al ricalcolo dai testi.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pandas.api.types import is_scalar # Importiamo il controllo specifico\n",
    "\n",
    "## 1. Funzione per contare le parole nel testo (Versione 3)\n",
    "\n",
    "def conta_parole_in_testo_corretto(riga):\n",
    "    lista_parole = riga['swear_IT_words']\n",
    "    testo_lyrics = riga['lyrics']\n",
    "\n",
    "    # --- CORREZIONE ---\n",
    "    # 1. Controlla il testo (che √® sempre scalare)\n",
    "    if pd.isna(testo_lyrics):\n",
    "        return 0\n",
    "\n",
    "    # 2. Controlla la lista/array\n",
    "    # Prima controlla se √® uno scalare (es. np.nan o None)\n",
    "    if is_scalar(lista_parole):\n",
    "        if pd.isna(lista_parole):\n",
    "            return 0  # √à np.nan o None, quindi 0\n",
    "        else:\n",
    "            return 0  # √à uno scalare ma non nullo (es. un numero), non va bene\n",
    "    \n",
    "    # Se siamo qui, 'lista_parole' NON √® uno scalare,\n",
    "    # quindi √® una lista o un array. Ora possiamo controllarne la lunghezza.\n",
    "    if len(lista_parole) == 0:\n",
    "        return 0\n",
    "    # --- FINE CORREZIONE ---\n",
    "\n",
    "    conteggio_totale = 0\n",
    "    testo_lower = testo_lyrics.lower()\n",
    "\n",
    "    for parola in lista_parole:\n",
    "        parola_lower = str(parola).lower()\n",
    "        pattern = r'\\b' + re.escape(parola_lower) + r'\\b'\n",
    "        occorrenze = re.findall(pattern, testo_lower)\n",
    "        conteggio_totale += len(occorrenze)\n",
    "\n",
    "    return conteggio_totale\n",
    "\n",
    "# --- ESECUZIONE DEL CONTROLLO ---\n",
    "\n",
    "# 1. Calcola il nuovo conteggio applicando la funzione CORRETTA\n",
    "print(\"1/3: Riconteggio delle parole nei testi (pu√≤ richiedere tempo)...\")\n",
    "df['conteggio_calcolato'] = df.apply(conta_parole_in_testo_corretto, axis=1)\n",
    "\n",
    "# 2. Prepara il conteggio originale\n",
    "df['conteggio_originale'] = df['swear_IT'].fillna(0).astype(int)\n",
    "\n",
    "# 3. Confronta i due conteggi\n",
    "print(\"2/3: Confronto dei conteggi...\")\n",
    "incoerenze = df[df['conteggio_originale'] != df['conteggio_calcolato']]\n",
    "\n",
    "# --- RISULTATO ---\n",
    "print(\"3/3: Controllo completato.\")\n",
    "if incoerenze.empty:\n",
    "    print(\"\\n‚úÖ Controllo superato! Tutti i conteggi 'swear_IT' corrispondono al ricalcolo dai testi.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Trovate {len(incoerenze)} righe incoerenti:\")\n",
    "    print(incoerenze[['artist', 'title', 'conteggio_originale', 'conteggio_calcolato', 'swear_IT_words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "56733761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3: Riconteggio delle parole nei testi (pu√≤ richiedere tempo)...\n",
      "2/3: Confronto dei conteggi...\n",
      "3/3: Controllo completato.\n",
      "\n",
      "‚úÖ Controllo superato! Tutti i conteggi 'swear_EN' corrispondono al ricalcolo dai testi.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pandas.api.types import is_scalar # Importiamo il controllo specifico\n",
    "\n",
    "## 1. Funzione per contare le parole nel testo (Versione 3)\n",
    "\n",
    "def conta_parole_in_testo_corretto(riga):\n",
    "    lista_parole = riga['swear_EN_words']\n",
    "    testo_lyrics = riga['lyrics']\n",
    "\n",
    "    # --- CORREZIONE ---\n",
    "    # 1. Controlla il testo (che √® sempre scalare)\n",
    "    if pd.isna(testo_lyrics):\n",
    "        return 0\n",
    "\n",
    "    # 2. Controlla la lista/array\n",
    "    # Prima controlla se √® uno scalare (es. np.nan o None)\n",
    "    if is_scalar(lista_parole):\n",
    "        if pd.isna(lista_parole):\n",
    "            return 0  # √à np.nan o None, quindi 0\n",
    "        else:\n",
    "            return 0  # √à uno scalare ma non nullo (es. un numero), non va bene\n",
    "    \n",
    "    # Se siamo qui, 'lista_parole' NON √® uno scalare,\n",
    "    # quindi √® una lista o un array. Ora possiamo controllarne la lunghezza.\n",
    "    if len(lista_parole) == 0:\n",
    "        return 0\n",
    "    # --- FINE CORREZIONE ---\n",
    "\n",
    "    conteggio_totale = 0\n",
    "    testo_lower = testo_lyrics.lower()\n",
    "\n",
    "    for parola in lista_parole:\n",
    "        parola_lower = str(parola).lower()\n",
    "        pattern = r'\\b' + re.escape(parola_lower) + r'\\b'\n",
    "        occorrenze = re.findall(pattern, testo_lower)\n",
    "        conteggio_totale += len(occorrenze)\n",
    "\n",
    "    return conteggio_totale\n",
    "\n",
    "# --- ESECUZIONE DEL CONTROLLO ---\n",
    "\n",
    "# 1. Calcola il nuovo conteggio applicando la funzione CORRETTA\n",
    "print(\"1/3: Riconteggio delle parole nei testi (pu√≤ richiedere tempo)...\")\n",
    "df['conteggio_calcolato'] = df.apply(conta_parole_in_testo_corretto, axis=1)\n",
    "\n",
    "# 2. Prepara il conteggio originale\n",
    "df['conteggio_originale'] = df['swear_EN'].fillna(0).astype(int)\n",
    "\n",
    "# 3. Confronta i due conteggi\n",
    "print(\"2/3: Confronto dei conteggi...\")\n",
    "incoerenze = df[df['conteggio_originale'] != df['conteggio_calcolato']]\n",
    "\n",
    "# --- RISULTATO ---\n",
    "print(\"3/3: Controllo completato.\")\n",
    "if incoerenze.empty:\n",
    "    print(\"\\n‚úÖ Controllo superato! Tutti i conteggi 'swear_EN' corrispondono al ricalcolo dai testi.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Trovate {len(incoerenze)} righe incoerenti:\")\n",
    "    print(incoerenze[['artist', 'title', 'conteggio_originale', 'conteggio_calcolato', 'swear_EN_words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "eed1eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PAROLE UNICHE ITALIANE (173) ---\n",
      "['cazzo', 'cesso', 'coglioni', 'figa', 'merda', 'palle', 'piscio', 'porca', 'stronzo', 'culo', 'frocio', 'puttana', 'sega', 'troia', 'bastardo', 'fottere', 'pompino', 'scopare', 'figo', 'cagare', 'fica', 'gay', 'zoccola', 'coglione', 'puttano', 'fottuto', 'cazzi', 'ricchione', 'stupido', 'vagina', 'selvaggio', 'fottuti', 'incazzato', 'cretino', 'sboccare', 'zanzara', 'fortuna', 'stupida', 'incazzare', 'cagna', 'grilletto', 'bastardi', 'toro', 'pippa', 'cazzata', 'sedere', 'mazzo', 'cretini', 'vaffanculo', 'fogne', 'scazzo', 'cogliona', 'cozza', 'jug', 'puttanata', 'sfiga', 'pisciare', 'scopata', 'checca', 'fesso', 'madonna', 'scassare', 'uccello', 'sfigata', 'battona', 'fregna', 'topa', 'pisciata', 'bagascia', 'maiala', 'mignotta', 'farabutto', 'chiappa', 'minchioni', 'fico', 'travestito', 'vacca', 'gnocca', 'bischero', 'idiozia', 'handicappato', 'leccaculo', 'pene', 'fregarsene', 'paraculo', 'bocchino', 'farabutti', 'granchio', 'blowjob', 'cappella', 'piccione', 'sborrare', 'fellatio', 'pisello', 'puttaniere', 'cazzeggio', 'cacca', 'stronzata', 'cagata', 'trombare', 'arrapato', 'fogna', 'water', 'cazzone', 'finocchio', 'puttanaio', 'sborra', 'scoreggia', 'feci', 'bernarda', 'sorca', 'cretina', 'bocchinaro', 'deretano', 'scrofa', 'fregare', 'pipa', 'chiavare', 'troiaggine', 'tetta', 'bombare', 'cazzeggiare', 'pugnetta', 'culattone', 'spagnola', 'cornuto', 'sveltina', 'rompicoglioni', 'seccatore', 'smerdare', 'incazzarsi', 'inculare', 'sputtanare', 'fava', 'cazzuto', 'merdina', 'maroni', 'strafottenza', 'arrapante', 'controcoglioni', 'controcazzi', 'fottersi', 'gigolo', 'rompipalle', 'fottio', 'peluria', 'zizza', 'glutei', 'merdaiolo', 'escremento', 'missionario', 'scazzato', 'chiavata', 'raspa', 'cunnu', 'arrapare', 'cacare', 'schizzare', 'vaccata', 'nerchia', 'pecorina', 'troiaio', 'pompinara', 'merdata', 'mezzasega', 'sgualdrina', 'cacata', 'spompinare', 'rottinculo', 'minchiata', 'coglionata', 'merdaio', 'segaiolo']\n"
     ]
    }
   ],
   "source": [
    "lista_parole_it = list(df['swear_IT_words'].explode().dropna().unique())\n",
    "\n",
    "# 2. Lista Inglese (EN)\n",
    "# Stessa identica logica\n",
    "lista_parole_en = list(df['swear_EN_words'].explode().dropna().unique())\n",
    "\n",
    "# 3. Stampa i risultati\n",
    "print(f\"--- PAROLE UNICHE ITALIANE ({len(lista_parole_it)}) ---\")\n",
    "print(lista_parole_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "05e95446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PAROLE UNICHE INGLESI (96) ---\n",
      "['bitch', 'fuck', 'porno', 'pussy', 'escort', 'negro', 'sex', 'sexy', 'shit', 'bastardo', 'bitches', 'cock', 'ass', 'slut', 'voyeur', 'anal', 'tranny', 'dick', 'nigga', 'threesome', 'vagina', 'porn', 'clit', 'nude', 'fucking', 'bullshit', 'motherfucker', 'xx', 'boobs', 'xxx', 'playboy', 'deepthroat', 'faggot', 'fisting', 'suck', 'cumming', 'milf', 'hardcore', 'cialis', 'fag', 'rapist', 'rape', 'dildo', 'viagra', 'rimming', 'sexo', 'hentai', 'blowjob', 'fuckin', 'gangbang', 'pedobear', 'fellatio', 'bastard', 'sexual', 'snatch', 'butt', 'cumshot', 'lolita', 'vulva', 'punany', 'panties', 'shitty', 'tits', 'topless', 'anus', 'bbw', 'bondage', 'cunt', 'scat', 'raping', 'shibari', 'poof', 'coon', 'skeet', 'domination', 'ecchi', 'sucks', 'creampie', 'cum', 'titty', 'spic', 'kinky', 'bukkake', 'cocks', 'pissing', 'asshole', 'busty', 'hooker', 'semen', 'horny', 'masturbation', 'neonazi', 'doggystyle', 'tit', 'nympho', 'nipple']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\n--- PAROLE UNICHE INGLESI ({len(lista_parole_en)}) ---\")\n",
    "print(lista_parole_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "f0e4a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione= (df['explicit']==False) & ((df['swear_IT']>0) | (df['swear_EN']>0))\n",
    "dati_filtrati = df.loc[condizione, ['explicit', 'swear_IT', 'swear_EN']]\n",
    "dati_filtrati\n",
    "df.loc[condizione,['explicit']] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "c3ea2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "condizione= (df['explicit']==True) & ((df['swear_IT']==0) & (df['swear_EN']==0))\n",
    "dati_filtrati = df.loc[condizione, ['explicit', 'swear_IT', 'swear_EN']]\n",
    "dati_filtrati\n",
    "df.loc[condizione,['explicit']] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "99fca526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creazione pattern RegEx in corso...\n",
      "Pattern creati.\n",
      "Inizio ricalcolo su tutto il DataFrame (pu√≤ richiedere tempo)...\n",
      "üìä Numero di record che verranno aggiornati: 3798\n",
      "üìã Creato 'df_swear_copy' con 3798 record (lo stato *prima* della modifica).\n",
      "Ricalcolo completato! Le colonne sono state aggiornate.\n"
     ]
    }
   ],
   "source": [
    "df_swear=df\n",
    "## 1. Preparazione: Creare i Pattern RegEx\n",
    "#    Questa √® la parte pi√π importante per la velocit√†.\n",
    "#    Trasformiamo ['a', 'b', 'c'] in r'\\b(a|b|c)\\b'\n",
    "\n",
    "def crea_pattern(lista_parole):\n",
    "    # 1. Assicura che siano tutte stringhe e minuscole\n",
    "    parole_pulite = [str(p).lower() for p in lista_parole if pd.notna(p)]\n",
    "    \n",
    "    # 2. Fai l'escape di ogni parola (per gestire caratteri come 'f**k')\n",
    "    parole_escaped = [re.escape(p) for p in parole_pulite]\n",
    "    \n",
    "    # 3. Uniscile con un OR (|)\n",
    "    pattern_string = \"|\".join(parole_escaped)\n",
    "    \n",
    "    # 4. Racchiudi in \\b (word boundary) per trovare solo parole intere\n",
    "    #    e compila il pattern RegEx.\n",
    "    return re.compile(r'\\b(' + pattern_string + r')\\b', re.IGNORECASE)\n",
    "\n",
    "print(\"Creazione pattern RegEx in corso...\")\n",
    "pattern_it = crea_pattern(lista_parole_it)\n",
    "pattern_en = crea_pattern(lista_parole_en)\n",
    "print(\"Pattern creati.\")\n",
    "\n",
    "\n",
    "## 2. Definire la Funzione di Ricalcolo\n",
    "#    Questa funzione verr√† applicata a OGNI RIGA del DataFrame\n",
    "\n",
    "def ricalcola_parole(riga):\n",
    "    testo = riga['lyrics']\n",
    "    \n",
    "    # Se il testo √® mancante, restituisci valori vuoti\n",
    "    if pd.isna(testo):\n",
    "        return 0, [], 0, [] # count_it, words_it, count_en, words_en\n",
    "\n",
    "    # --- Processo Italiano ---\n",
    "    # re.findall() trova TUTTE le occorrenze (anche duplicate)\n",
    "    matches_it = pattern_it.findall(testo.lower())\n",
    "    \n",
    "    # Il conteggio √® il numero totale di occorrenze\n",
    "    conteggio_it = len(matches_it)\n",
    "    # La lista di parole √® l'insieme unico (set) delle parole trovate\n",
    "    parole_uniche_it = list(set(matches_it))\n",
    "\n",
    "    # --- Processo Inglese ---\n",
    "    matches_en = pattern_en.findall(testo.lower())\n",
    "    conteggio_en = len(matches_en)\n",
    "    parole_uniche_en = list(set(matches_en))\n",
    "\n",
    "    return conteggio_it, parole_uniche_it, conteggio_en, parole_uniche_en\n",
    "\n",
    "\n",
    "## 3. Esecuzione e Aggiornamento\n",
    "#    Applichiamo la funzione all'intero DataFrame\n",
    "\n",
    "print(\"Inizio ricalcolo su tutto il DataFrame (pu√≤ richiedere tempo)...\")\n",
    "\n",
    "# 'axis=1' applica la funzione a ogni riga\n",
    "# 'result_type='expand'' divide il risultato della funzione (i 4 valori)\n",
    "# in 4 nuove colonne\n",
    "nuovi_valori = df_swear.apply(ricalcola_parole, axis=1, result_type='expand')\n",
    "\n",
    "nuovi_valori.columns = ['swear_IT_new', 'swear_IT_words_new', 'swear_EN_new', 'swear_EN_words_new']\n",
    "\n",
    "# Confrontiamo le vecchie colonne con le nuove\n",
    "# Usiamo .fillna(0) per i conteggi e .ne() (Not Equal) per le liste\n",
    "\n",
    "# 1. Confronto Conteggi\n",
    "cond_it_count = df_swear['swear_IT'].fillna(0).ne(nuovi_valori['swear_IT_new'])\n",
    "cond_en_count = df_swear['swear_EN'].fillna(0).ne(nuovi_valori['swear_EN_new'])\n",
    "\n",
    "# 2. Confronto Liste\n",
    "# .ne() gestisce correttamente il confronto tra liste e valori NaN/None\n",
    "cond_it_words = df_swear['swear_IT_words'].ne(nuovi_valori['swear_IT_words_new'])\n",
    "cond_en_words = df_swear['swear_EN_words'].ne(nuovi_valori['swear_EN_words_new'])\n",
    "\n",
    "# 3. Condizione Totale: la riga √® cambiata se ALMENO UNO dei 4 campi √® diverso\n",
    "condizione_cambiati = (cond_it_count | cond_en_count | cond_it_words | cond_en_words)\n",
    "\n",
    "# 4. Stampa e Copia (come richiesto)\n",
    "num_cambiati = condizione_cambiati.sum()\n",
    "print(f\"üìä Numero di record che verranno aggiornati: {num_cambiati}\")\n",
    "\n",
    "# Creiamo la copia delle righe *originali* che stanno per cambiare\n",
    "df_swear_copy = df_swear[condizione_cambiati].copy()\n",
    "print(f\"üìã Creato 'df_swear_copy' con {len(df_swear_copy)} record (lo stato *prima* della modifica).\")\n",
    "\n",
    "# Assegna i nuovi valori alle colonne corrette del DataFrame originale\n",
    "# (sovrascrivendo i vecchi dati)\n",
    "df_swear[['swear_IT', 'swear_IT_words', 'swear_EN', 'swear_EN_words']] = nuovi_valori\n",
    "\n",
    "print(\"Ricalcolo completato! Le colonne sono state aggiornate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6d82b",
   "metadata": {},
   "source": [
    "We discovered that the dataset was probably created by starting with a fixed swear words list but this list doesn't include plural and leads to not accurate records both in the swear_word collection, count and the explicit column.\n",
    "We decided to just fix the explicit column according to our swear words counts and not manually insert the plural or the other word forms in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "bc699959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['conteggio_calcolato', 'conteggio_originale'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "34bde8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11166 entries, 0 to 11165\n",
      "Data columns (total 48 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   id_artist             11166 non-null  object        \n",
      " 1   name_artist           11166 non-null  object        \n",
      " 2   title                 11166 non-null  string        \n",
      " 3   featured_artists      11166 non-null  object        \n",
      " 4   language              11036 non-null  object        \n",
      " 5   album                 11161 non-null  object        \n",
      " 6   swear_IT              11166 non-null  int64         \n",
      " 7   swear_EN              11166 non-null  int64         \n",
      " 8   swear_IT_words        11166 non-null  object        \n",
      " 9   swear_EN_words        11166 non-null  object        \n",
      " 10  n_sentences           10963 non-null  float64       \n",
      " 11  n_tokens              10963 non-null  float64       \n",
      " 12  tokens_per_sent       10963 non-null  float64       \n",
      " 13  char_per_tok          11090 non-null  float64       \n",
      " 14  lexical_density       11090 non-null  float64       \n",
      " 15  avg_token_per_clause  10963 non-null  float64       \n",
      " 16  bpm                   11102 non-null  float64       \n",
      " 17  centroid              11102 non-null  float64       \n",
      " 18  rolloff               11102 non-null  float64       \n",
      " 19  flux                  11102 non-null  float64       \n",
      " 20  rms                   11102 non-null  float64       \n",
      " 21  zcr                   11102 non-null  float64       \n",
      " 22  flatness              11102 non-null  float64       \n",
      " 23  spectral_complexity   11102 non-null  float64       \n",
      " 24  pitch                 11102 non-null  float64       \n",
      " 25  loudness              11102 non-null  float64       \n",
      " 26  album_type            11088 non-null  category      \n",
      " 27  disc_number           11088 non-null  Int64         \n",
      " 28  track_number          11088 non-null  Int64         \n",
      " 29  duration_ms           11088 non-null  float64       \n",
      " 30  explicit              11039 non-null  object        \n",
      " 31  popularity            11088 non-null  float64       \n",
      " 32  album_image           11088 non-null  string        \n",
      " 33  id_album              11161 non-null  object        \n",
      " 34  lyrics                11036 non-null  string        \n",
      " 35  gender                11166 non-null  category      \n",
      " 36  birth_date            8588 non-null   datetime64[ns]\n",
      " 37  birth_place           8588 non-null   category      \n",
      " 38  nationality           8557 non-null   category      \n",
      " 39  description           10028 non-null  string        \n",
      " 40  active_start          11166 non-null  datetime64[ns]\n",
      " 41  province              8467 non-null   category      \n",
      " 42  region                8024 non-null   category      \n",
      " 43  country               8467 non-null   category      \n",
      " 44  latitude              8588 non-null   float64       \n",
      " 45  longitude             8588 non-null   float64       \n",
      " 46  swear IT words        0 non-null      object        \n",
      " 47  release_date          11149 non-null  datetime64[ns]\n",
      "dtypes: Int64(2), category(7), datetime64[ns](3), float64(20), int64(2), object(10), string(4)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb99ad",
   "metadata": {},
   "source": [
    "## Stat_pageviews\n",
    "\n",
    "Drop due to 60% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "eb0845fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['stats_pageviews'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465abd00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
